{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T08:46:12.567823Z",
     "start_time": "2022-04-22T08:46:10.857394Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from torch.cuda.amp import autocast \n",
    "from torch.cuda.amp import GradScaler\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchsummary import summary\n",
    "import time\n",
    "from torch.nn import init\n",
    "from typing import Union, List, Dict, Any, Optional, cast\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T08:46:12.583774Z",
     "start_time": "2022-04-22T08:46:12.568817Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T08:46:12.599737Z",
     "start_time": "2022-04-22T08:46:12.584774Z"
    }
   },
   "outputs": [],
   "source": [
    "#保存训练数据和模型\n",
    "data_csv_path = \"D:\\\\OneModel\\\\qyxx-eca_net-KA-MCML-information.csv\"   #修改此处文件名 \n",
    "model_save_path = \"D:\\\\OneModel\\\\qyxx-eca_net-KA-MCML-information.pkl\"  #修改此处文件名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T08:46:12.615690Z",
     "start_time": "2022-04-22T08:46:12.601728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 200 learning_rate: 0.0005 batch_size: 128\n"
     ]
    }
   ],
   "source": [
    "train_path = \"D:\\\\Dataset\\\\inputdataset\\\\train\"\n",
    "val_path =  \"D:\\\\Dataset\\\\inputdataset\\\\val\"\n",
    "master_path = \"D:\\\\Dataset\\\\CK_division\\\\division\"\n",
    "csv_path = \"D:\\\\Dataset\\\\provincial_characteristics.csv\"\n",
    "\n",
    "#模型批次大小\n",
    "batch_size = 128\n",
    "resume = True\n",
    "#动态学习率，学习率和循环次数增加\n",
    "lr = 5e-4\n",
    "epochs = 200\n",
    "D_epoch = 0 \n",
    "best_acc  = 0\n",
    "print(\"epochs:\",epochs,\"learning_rate:\",lr,\"batch_size:\",batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T08:46:12.646607Z",
     "start_time": "2022-04-22T08:46:12.616690Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU\n",
      "divice is  cuda:0\n"
     ]
    }
   ],
   "source": [
    "#设备选取\n",
    "flag = torch.cuda.is_available()\n",
    "if flag:\n",
    "    print(\"GPU\")\n",
    "else:\n",
    "    print(\"CPU\")\n",
    "ngpu = 1\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "#查看显卡名称\n",
    "#torch.cuda.get_device_name()\n",
    "print(\"divice is \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T08:46:12.662565Z",
     "start_time": "2022-04-22T08:46:12.647604Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class DataSet_pre(Dataset):\n",
    "    '''\n",
    "    初始化函数\n",
    "    root文件路径，resize转换大小，mode训练还是测试或者其他的\n",
    "    name2label标签集合\n",
    "    没有编写输入错误的mode处理方法\n",
    "    master_path 分割文件夹主路径\n",
    "    csv_path 位置信息存储csv路径\n",
    "    '''\n",
    "    def __init__(self, root, resize,master_path,csv_path):\n",
    "        super(DataSet_pre, self).__init__()\n",
    "        self.root = root\n",
    "        self.resize = resize\n",
    "        self.name2label = {} # 给类别进行数字标签 类似于 'anger':1,...\n",
    "        #获取名称\n",
    "        for name in sorted(os.listdir(os.path.join(root))):\n",
    "            if not os.path.isdir(os.path.join(root, name)):\n",
    "                continue\n",
    "            self.name2label[name] = len(self.name2label.keys())\n",
    "\n",
    "        print(self.name2label)  #查看类别\n",
    "        self.images, self.labels = [], []\n",
    "          # 'pokemon\\\\mewtwo\\\\00001.png\n",
    "        for name in self.name2label.keys():\n",
    "            \n",
    "            dataset_classes_path = os.path.join(self.root,name)\n",
    "            image_name_list = os.listdir(dataset_classes_path)\n",
    "            for i in image_name_list:\n",
    "                self.images.append(os.path.join(dataset_classes_path,i))\n",
    "                self.labels.append(self.name2label[name])\n",
    "           \n",
    "\n",
    "        self.master_path = master_path\n",
    "        self.csv_path = csv_path\n",
    "\n",
    "    def __len__(self):\n",
    "        #不是总数量，根据划分数据集所添加的\n",
    "        return len(self.images)\n",
    "    \n",
    "    def data_search(self,path,master_path):\n",
    "        Transform = transforms.Compose([\n",
    "            lambda x:Image.open(x).convert('RGB'), # string path= > image data\n",
    "            transforms.Resize((24,24)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        ImageFileName = str(path).split('\\\\')[-1]\n",
    "        #获取读取图片类别anger\n",
    "        expression_type = ImageFileName.split('_')[0]\n",
    "        #获取指定类别路径 \n",
    "        Path_joining_together = os.path.join(master_path,expression_type)\n",
    "        #获取指定图片类别路径\n",
    "        left_eye = Transform(os.path.join(Path_joining_together,'left_eye'+\"\\\\\"+str(ImageFileName)))\n",
    "        mouth = Transform(os.path.join(Path_joining_together,'mouth'+\"\\\\\"+str(ImageFileName)))\n",
    "        nose = Transform(os.path.join(Path_joining_together,'nose'+\"\\\\\"+str(ImageFileName)))\n",
    "        right_eye = Transform(os.path.join(Path_joining_together,'right_eye'+\"\\\\\"+str(ImageFileName)))\n",
    "        return [left_eye,mouth,nose,right_eye]\n",
    "    \n",
    "    def posi_info(self,path,positional_information):\n",
    "        df = pd.read_csv(positional_information)\n",
    "        try:\n",
    "                #获取图片名称\n",
    "                ImageFileName = str(path).split('\\\\')[-1]\n",
    "#                 print(ImageFileName)  #anger_0.png\n",
    "                ImageName = df[df['image_name'].isin([ImageFileName])]\n",
    "                LeftEye_index = ImageName['left_eye'].index.tolist()[0]\n",
    "                RightEye_index = ImageName['right_eye'].index.tolist()[0]\n",
    "                Nose_index = ImageName['nose'].index.tolist()[0]\n",
    "                \n",
    "                Mouth_index = ImageName['mouth'].index.tolist()[0]\n",
    "                LeftEye_info = df.at[LeftEye_index,'left_eye']\n",
    "                RightEye_info = df.at[RightEye_index,'right_eye']\n",
    "                Nose_info = df.at[Nose_index,'nose']\n",
    "                Mouth_info = df.at[Mouth_index,'mouth']\n",
    "                \n",
    "                one = torch.Tensor(eval(LeftEye_info))\n",
    "#                 print(type(one))  #list\n",
    "                two = torch.Tensor(eval(RightEye_info))\n",
    "                three = torch.Tensor(eval(Nose_info))\n",
    "                four = torch.Tensor(eval(Mouth_info))\n",
    "        except IndexError:\n",
    "                print('error...')\n",
    "                print(path)\n",
    "                print(ImageFileName)\n",
    "        \n",
    "        return one,two,three,four\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # idx  [0~len(images)]\n",
    "        # self.images, self.labels\n",
    "        # img: 'pokemon\\\\bulbasaur\\\\00000000.png'\n",
    "        # label: 0\n",
    "        path, label = self.images[idx], self.labels[idx]\n",
    "\n",
    "        Transform = transforms.Compose([\n",
    "            lambda x:Image.open(x).convert('RGB'), # string path= > image data\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "        img = Transform(path)\n",
    "        division_list = self.data_search(path,self.master_path)\n",
    "        pn_list = self.posi_info(path,self.csv_path)\n",
    "        label = torch.tensor(label)\n",
    "        return img,label,division_list,pn_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T08:46:12.678527Z",
     "start_time": "2022-04-22T08:46:12.663561Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'anger': 0, 'contempt': 1, 'disgust': 2, 'fear': 3, 'happy': 4, 'sadness': 5, 'surprise': 6}\n",
      "{'anger': 0, 'contempt': 1, 'disgust': 2, 'fear': 3, 'happy': 4, 'sadness': 5, 'surprise': 6}\n"
     ]
    }
   ],
   "source": [
    "#参数设定\n",
    "train_data = DataSet_pre(root=train_path,resize=224,master_path = master_path,csv_path = csv_path)\n",
    "data_train = DataLoader(train_data, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "#root, resize,mode,master_path,csv_path\n",
    "val_data = DataSet_pre(root=val_path,resize=224,master_path = master_path,csv_path = csv_path)\n",
    "data_val = DataLoader(val_data, batch_size=batch_size, shuffle=True,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T08:46:12.710442Z",
     "start_time": "2022-04-22T08:46:12.679519Z"
    },
    "code_folding": [
     0,
     23,
     29,
     62,
     103
    ]
   },
   "outputs": [],
   "source": [
    "class eca_layer(nn.Module):\n",
    "    \"\"\"Constructs a ECA module.\n",
    "    Args:\n",
    "        channel: Number of channels of the input feature map\n",
    "        k_size: Adaptive selection of kernel size\n",
    "    \"\"\"\n",
    "    def __init__(self, channel, k_size=3):\n",
    "        super(eca_layer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.conv = nn.Conv1d(1, 1, kernel_size=k_size, padding=(k_size - 1) // 2, bias=False) \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # feature descriptor on the global spatial information\n",
    "        y = self.avg_pool(x)\n",
    "\n",
    "        # Two different branches of ECA module\n",
    "        y = self.conv(y.squeeze(-1).transpose(-1, -2)).transpose(-1, -2).unsqueeze(-1)\n",
    "\n",
    "        # Multi-scale information fusion\n",
    "        y = self.sigmoid(y)\n",
    "\n",
    "        return x * y.expand_as(x)\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class ECABasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, k_size=3):\n",
    "        super(ECABasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.eca = eca_layer(planes, k_size)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.eca(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ECABottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, k_size=3):\n",
    "        super(ECABottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.eca = eca_layer(planes * 4, k_size)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        out = self.eca(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, k_size=[3, 3, 3, 3]):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], int(k_size[0]))\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], int(k_size[1]), stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], int(k_size[2]), stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], int(k_size[3]), stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, k_size, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, k_size))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, k_size=k_size))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def eca_resnet18(k_size=[3, 5, 7, 7], num_classes=1_000, pretrained=False):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    Args:\n",
    "        k_size: Adaptive selection of kernel size\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        num_classes:The classes of classification\n",
    "    \"\"\"\n",
    "    model = ResNet(ECABasicBlock, [2, 2, 2, 2], num_classes=num_classes, k_size=k_size)\n",
    "    model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T08:46:12.853168Z",
     "start_time": "2022-04-22T08:46:12.711435Z"
    }
   },
   "outputs": [],
   "source": [
    "eca_net = eca_resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T08:46:12.883092Z",
     "start_time": "2022-04-22T08:46:12.856161Z"
    },
    "code_folding": [
     0,
     37,
     64,
     75
    ]
   },
   "outputs": [],
   "source": [
    "class ECAAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.gap=nn.AdaptiveAvgPool2d(1)\n",
    "        self.maxpool=nn.AdaptiveMaxPool2d(1)\n",
    "        self.conv=nn.Conv1d(1,1,kernel_size=kernel_size,padding=3)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "        self.init_weights()\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                init.constant_(m.weight, 1)\n",
    "                init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                init.normal_(m.weight, std=0.001)\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        avp_result =self.gap(x) #bs,c,1,1\n",
    "        max_result = self.maxpool(x)\n",
    "        \n",
    "        avp_result=avp_result.squeeze(-1).permute(0,2,1) #bs,1,c\n",
    "        max_result=max_result.squeeze(-1).permute(0,2,1) #bs,1,c\n",
    "        \n",
    "        avp_result=self.conv(avp_result) #bs,1,c\n",
    "        max_result=self.conv(max_result) #bs,1,c\n",
    "        \n",
    "        y=self.sigmoid(max_result + avp_result) #bs,1,c\n",
    "        y=y.permute(0,2,1).unsqueeze(-1) #bs,c,1,1\n",
    "        return x*y.expand_as(x)\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self,kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.conv=nn.Conv2d(2,1,kernel_size=kernel_size,padding=3)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "        self.init_weights()\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                init.constant_(m.weight, 1)\n",
    "                init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                init.normal_(m.weight, std=0.001)\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "    def forward(self, x) :\n",
    "        max_result,_=torch.max(x,dim=1,keepdim=True)\n",
    "        avg_result=torch.mean(x,dim=1,keepdim=True)\n",
    "        result=torch.cat([max_result,avg_result],1)\n",
    "        output=self.conv(result)\n",
    "        output=self.sigmoid(output)\n",
    "        return x*output\n",
    "    \n",
    "class CA_SA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.eca = ECAAttention()\n",
    "        self.sa = SpatialAttention()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.eca(x)\n",
    "        x = self.sa(x)\n",
    "        return x\n",
    "    \n",
    "class K_Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.eca = ECAAttention()\n",
    "        self.sa = SpatialAttention()\n",
    "        self.eca_sa = CA_SA()\n",
    "    def forward(self,x):\n",
    "        out1 = self.eca_sa(x)\n",
    "        out2 = self.eca(x) + self.sa(x)\n",
    "        return out2 + out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T08:46:12.899050Z",
     "start_time": "2022-04-22T08:46:12.884085Z"
    }
   },
   "outputs": [],
   "source": [
    "class SKNet(nn.Module):\n",
    "    def __init__(self, num_class=7):\n",
    "        super(SKNet, self).__init__()\n",
    "        self.features = nn.Sequential(*list(eca_net.children())[:-2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.KA = K_Attention()\n",
    "        self.fc = nn.Linear(512*4, num_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.features(x)\n",
    "        out1 = self.KA(x)\n",
    "        out2 = self.KA(x)\n",
    "        out3 = self.KA(x)\n",
    "        out4 = self.KA(x)\n",
    "        out = torch.cat((out1,out2,out3,out4),dim=1)\n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out,1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T08:46:13.119456Z",
     "start_time": "2022-04-22T08:46:12.900042Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SKNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): ECABasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (eca): eca_layer(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (1): ECABasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (eca): eca_layer(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): ECABasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (eca): eca_layer(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv): Conv1d(1, 1, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ECABasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (eca): eca_layer(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv): Conv1d(1, 1, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): ECABasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (eca): eca_layer(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv): Conv1d(1, 1, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ECABasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (eca): eca_layer(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv): Conv1d(1, 1, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): ECABasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (eca): eca_layer(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv): Conv1d(1, 1, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ECABasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (eca): eca_layer(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv): Conv1d(1, 1, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (KA): K_Attention(\n",
       "    (eca): ECAAttention(\n",
       "      (gap): AdaptiveAvgPool2d(output_size=1)\n",
       "      (maxpool): AdaptiveMaxPool2d(output_size=1)\n",
       "      (conv): Conv1d(1, 1, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (sa): SpatialAttention(\n",
       "      (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (eca_sa): CA_SA(\n",
       "      (eca): ECAAttention(\n",
       "        (gap): AdaptiveAvgPool2d(output_size=1)\n",
       "        (maxpool): AdaptiveMaxPool2d(output_size=1)\n",
       "        (conv): Conv1d(1, 1, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (sa): SpatialAttention(\n",
       "        (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=2048, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"D:\\\\OneModel\\\\迁移学习\\\\ECANet\\\\ISA-MCML\\\\qyxx-eca_net-KA-MCML.pkl\"\n",
    "sknet = SKNet()\n",
    "checkpoint = torch.load(model_path)\n",
    "sknet.load_state_dict(checkpoint['model'])\n",
    "del checkpoint\n",
    "for p in sknet.parameters():\n",
    "    p.requires_grad=False\n",
    "sknet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T08:46:13.135418Z",
     "start_time": "2022-04-22T08:46:13.120454Z"
    }
   },
   "outputs": [],
   "source": [
    "class X_model(nn.Module):\n",
    "    def __init__(self, num_class=7):\n",
    "        super(X_model, self).__init__()\n",
    "        self.features = nn.Sequential(*list(sknet.children())[:-1])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.KA = K_Attention()\n",
    "        self.fc = nn.Linear(556, num_class)\n",
    "\n",
    "    def forward(self,x,division_list,pn_list):\n",
    "        division_list[0] = division_list[0].to(device)\n",
    "        division_list[1] = division_list[1].to(device)\n",
    "        division_list[2] = division_list[2].to(device)\n",
    "        division_list[3] = division_list[3].to(device)\n",
    "        pn_list[0] = pn_list[0].to(device)\n",
    "        pn_list[1] = pn_list[1].to(device)\n",
    "        pn_list[2] = pn_list[2].to(device)\n",
    "        pn_list[3] = pn_list[3].to(device)\n",
    "        #原图特征提取\n",
    "        x = torch.flatten(self.avgpool(self.features(x)),1)\n",
    "        #分割特征提取，深层注意力机制\n",
    "        out1 = torch.flatten(self.avgpool(self.KA(division_list[0])),1)\n",
    "        out2 = torch.flatten(self.avgpool(self.KA(division_list[1])),1)\n",
    "        out3 = torch.flatten(self.avgpool(self.KA(division_list[2])),1)\n",
    "        out4 = torch.flatten(self.avgpool(self.KA(division_list[3])),1)\n",
    "\n",
    "        out = torch.cat((x,out1,out2,out3,out4,pn_list[0],pn_list[1],pn_list[2],pn_list[3]),dim=1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T08:46:13.151375Z",
     "start_time": "2022-04-22T08:46:13.136410Z"
    }
   },
   "outputs": [],
   "source": [
    "#版本3，矩阵优化\n",
    "class MCML_Loss(nn.Module):\n",
    "    #第二种实现，F(x) 维度 （bs，512）\n",
    "    def __init__(self):\n",
    "        super(MCML_Loss, self).__init__()\n",
    "        self.KL = nn.KLDivLoss(reduction=\"batchmean\")  #KL散度\n",
    "    def forward(self, x, labels):\n",
    "#         one = time.time()\n",
    "        label = labels.cpu()\n",
    "        bs = x.shape[0]\n",
    "        P  = torch.ones([bs, bs]).cuda()   #根据真实标签计算条件概率\n",
    "        D = torch.cdist(x, x, p=2)\n",
    "        Q_E = (-D).exp()\n",
    "        Q_E = Q_E - torch.diag_embed(torch.diag(Q_E))  #设置i=j的元素都为0，不用担心log0的存在 KL散度y(logy-logy')  其中y=y'=0 \n",
    "        fm_sum = torch.sum(Q_E,dim=1)  #构建条件概率分母   每一行运算出的结果 张量形状（bs）\n",
    "        fm_sum = torch.reshape(fm_sum,(-1,1))\n",
    "        Q = torch.div(Q_E, fm_sum)\n",
    "        number = 0\n",
    "        for i in label:\n",
    "            indexs = np.argwhere(label==i)\n",
    "            for j in indexs:\n",
    "                P[number][j] = 0\n",
    "            number +=1\n",
    "        # input should be a distribution in the log space\n",
    "        q = F.log_softmax(Q)\n",
    "        # Sample a batch of distributions. Usually this would come from the dataset\n",
    "        p = F.softmax(P)\n",
    "        loss = self.KL(q, p)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T08:46:13.183285Z",
     "start_time": "2022-04-22T08:46:13.152367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_model(\n",
      "  (features): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (4): Sequential(\n",
      "        (0): ECABasicBlock(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (eca): eca_layer(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (conv): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (1): ECABasicBlock(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (eca): eca_layer(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (conv): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): ECABasicBlock(\n",
      "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (eca): eca_layer(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (conv): Conv1d(1, 1, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): ECABasicBlock(\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (eca): eca_layer(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (conv): Conv1d(1, 1, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (6): Sequential(\n",
      "        (0): ECABasicBlock(\n",
      "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (eca): eca_layer(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (conv): Conv1d(1, 1, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): ECABasicBlock(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (eca): eca_layer(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (conv): Conv1d(1, 1, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (7): Sequential(\n",
      "        (0): ECABasicBlock(\n",
      "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (eca): eca_layer(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (conv): Conv1d(1, 1, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): ECABasicBlock(\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (eca): eca_layer(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (conv): Conv1d(1, 1, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): AdaptiveAvgPool2d(output_size=1)\n",
      "    (2): K_Attention(\n",
      "      (eca): ECAAttention(\n",
      "        (gap): AdaptiveAvgPool2d(output_size=1)\n",
      "        (maxpool): AdaptiveMaxPool2d(output_size=1)\n",
      "        (conv): Conv1d(1, 1, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (sa): SpatialAttention(\n",
      "        (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (eca_sa): CA_SA(\n",
      "        (eca): ECAAttention(\n",
      "          (gap): AdaptiveAvgPool2d(output_size=1)\n",
      "          (maxpool): AdaptiveMaxPool2d(output_size=1)\n",
      "          (conv): Conv1d(1, 1, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (sa): SpatialAttention(\n",
      "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (KA): K_Attention(\n",
      "    (eca): ECAAttention(\n",
      "      (gap): AdaptiveAvgPool2d(output_size=1)\n",
      "      (maxpool): AdaptiveMaxPool2d(output_size=1)\n",
      "      (conv): Conv1d(1, 1, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (sigmoid): Sigmoid()\n",
      "    )\n",
      "    (sa): SpatialAttention(\n",
      "      (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "      (sigmoid): Sigmoid()\n",
      "    )\n",
      "    (eca_sa): CA_SA(\n",
      "      (eca): ECAAttention(\n",
      "        (gap): AdaptiveAvgPool2d(output_size=1)\n",
      "        (maxpool): AdaptiveMaxPool2d(output_size=1)\n",
      "        (conv): Conv1d(1, 1, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (sa): SpatialAttention(\n",
      "        (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=556, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#to(device)将模型加入GPU中加速计算\n",
    "model = X_model().to(device)\n",
    "#设置优化器\n",
    "mcml_loss = MCML_Loss().to(device)\n",
    "\n",
    "params = list(model.parameters()) + list(mcml_loss.parameters())\n",
    "optimizer = optim.AdamW(params, lr=lr)\n",
    "\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "#设置损失函数\n",
    "criteon = nn.CrossEntropyLoss().to(device)\n",
    "#余弦衰减学习率\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=80, eta_min=0)\n",
    "#形如TensorFlow中的summary函数输出模型参数\n",
    "# summary(model, input_size=[(3, 224, 224)], batch_size=batch_size, device=\"cuda\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T08:46:13.199242Z",
     "start_time": "2022-04-22T08:46:13.184282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "执行结束\n"
     ]
    }
   ],
   "source": [
    "#测试函数\n",
    "def evalute_(model,val_loader):\n",
    "    model.eval()\n",
    "    test_loss2 = 0.0\n",
    "    test_corrects2 = 0.0\n",
    "    number = 0\n",
    "    for batchidx,(x,label,division_list,pn_list) in enumerate(val_loader):\n",
    "#         print(number)\n",
    "    #torch.cuda.empty_cache()  #清除非必要GPU缓存，但是我建议不要在训练中使用此句，这可能会损失你相当多的时间\n",
    "        number = number + 1\n",
    "        x, label = x.to(device), label.to(device)\n",
    "        #测试函数中加入no_grad()，如果不加会增加计算和显存\n",
    "        with torch.no_grad():\n",
    "            y1 = model(x,division_list,pn_list)\n",
    "            #虽然可以直接使用max函数，但是我建议在y1的比较重你最好使用F.softmax(y1,dim=1)，这样可能会有更好的效果，我在训练中使用了它\n",
    "            _, preds1 = torch.max(F.softmax(y1,dim=1), 1)\n",
    "            loss = criteon(y1, label)  \n",
    "            \n",
    "            test_loss2 += loss.item()*batch_size\n",
    "            test_corrects2 += torch.sum(preds1 == label.data)\n",
    "    #由于使用了最后一次抛弃，我不能使用全部测试集作为分母，这样会使最后的准确率变小\n",
    "    test_loss1 = test_loss2 / (number*batch_size)\n",
    "    test_acc1 = test_corrects2.double() / (number*batch_size)\n",
    "#     print(\"TestDataset loss is \", test_loss1,\"TestDataset accuracy is \",test_acc1)\n",
    "    return test_acc1, test_loss1\n",
    "print(\"执行结束\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T09:28:29.926982Z",
     "start_time": "2022-04-22T08:46:13.200241Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "The Model-Train-Time spent  0 min 15.98 s\n",
      "Accuracy : Train is 0.5377604166666666 , Valid is 0.65625 ;  Loss : Train is  1.6206334233283997 ,Valid is 1.2676005363464355\n",
      "覆盖最好的模型...\n",
      "epoch: 1\n",
      "The Model-Train-Time spent  0 min 10.96 s\n",
      "Accuracy : Train is 0.7252604166666666 , Valid is 0.6796875 ;  Loss : Train is  1.1117705702781677 ,Valid is 0.9398254156112671\n",
      "覆盖最好的模型...\n",
      "epoch: 2\n",
      "The Model-Train-Time spent  0 min 10.78 s\n",
      "Accuracy : Train is 0.7526041666666666 , Valid is 0.75 ;  Loss : Train is  0.8566168447335561 ,Valid is 0.7502306699752808\n",
      "覆盖最好的模型...\n",
      "epoch: 3\n",
      "The Model-Train-Time spent  0 min 10.73 s\n",
      "Accuracy : Train is 0.7643229166666666 , Valid is 0.8046875 ;  Loss : Train is  0.7240327696005503 ,Valid is 0.6163817048072815\n",
      "覆盖最好的模型...\n",
      "epoch: 4\n",
      "The Model-Train-Time spent  0 min 10.69 s\n",
      "Accuracy : Train is 0.7916666666666666 , Valid is 0.8046875 ;  Loss : Train is  0.6521100699901581 ,Valid is 0.5340917110443115\n",
      "epoch: 5\n",
      "The Model-Train-Time spent  0 min 10.62 s\n",
      "Accuracy : Train is 0.8177083333333333 , Valid is 0.8359375 ;  Loss : Train is  0.5905316472053528 ,Valid is 0.4936487674713135\n",
      "覆盖最好的模型...\n",
      "epoch: 6\n",
      "The Model-Train-Time spent  0 min 10.55 s\n",
      "Accuracy : Train is 0.8138020833333333 , Valid is 0.796875 ;  Loss : Train is  0.5809446523586909 ,Valid is 0.5241838693618774\n",
      "epoch: 7\n",
      "The Model-Train-Time spent  0 min 10.69 s\n",
      "Accuracy : Train is 0.82421875 , Valid is 0.8359375 ;  Loss : Train is  0.5435020824273428 ,Valid is 0.45645803213119507\n",
      "epoch: 8\n",
      "The Model-Train-Time spent  0 min 10.86 s\n",
      "Accuracy : Train is 0.8333333333333333 , Valid is 0.8125 ;  Loss : Train is  0.5265091160933176 ,Valid is 0.5794646739959717\n",
      "epoch: 9\n",
      "The Model-Train-Time spent  0 min 10.85 s\n",
      "Accuracy : Train is 0.8385416666666666 , Valid is 0.8359375 ;  Loss : Train is  0.5110916544993719 ,Valid is 0.4708236753940582\n",
      "epoch: 10\n",
      "The Model-Train-Time spent  0 min 10.80 s\n",
      "Accuracy : Train is 0.83984375 , Valid is 0.7890625 ;  Loss : Train is  0.4952923705180486 ,Valid is 0.49110689759254456\n",
      "epoch: 11\n",
      "The Model-Train-Time spent  0 min 10.91 s\n",
      "Accuracy : Train is 0.8502604166666666 , Valid is 0.8359375 ;  Loss : Train is  0.48124993840853375 ,Valid is 0.4319213032722473\n",
      "epoch: 12\n",
      "The Model-Train-Time spent  0 min 10.83 s\n",
      "Accuracy : Train is 0.8411458333333333 , Valid is 0.8203125 ;  Loss : Train is  0.48740536471207935 ,Valid is 0.44734272360801697\n",
      "epoch: 13\n",
      "The Model-Train-Time spent  0 min 10.92 s\n",
      "Accuracy : Train is 0.8515625 , Valid is 0.828125 ;  Loss : Train is  0.4687512417634328 ,Valid is 0.46314573287963867\n",
      "epoch: 14\n",
      "The Model-Train-Time spent  0 min 10.90 s\n",
      "Accuracy : Train is 0.8515625 , Valid is 0.828125 ;  Loss : Train is  0.4633219639460246 ,Valid is 0.45815902948379517\n",
      "epoch: 15\n",
      "The Model-Train-Time spent  0 min 10.72 s\n",
      "Accuracy : Train is 0.8463541666666666 , Valid is 0.84375 ;  Loss : Train is  0.4577257037162781 ,Valid is 0.40988823771476746\n",
      "覆盖最好的模型...\n",
      "epoch: 16\n",
      "The Model-Train-Time spent  0 min 10.66 s\n",
      "Accuracy : Train is 0.859375 , Valid is 0.859375 ;  Loss : Train is  0.4395761440197627 ,Valid is 0.3483090400695801\n",
      "覆盖最好的模型...\n",
      "epoch: 17\n",
      "The Model-Train-Time spent  0 min 10.73 s\n",
      "Accuracy : Train is 0.8567708333333333 , Valid is 0.8671875 ;  Loss : Train is  0.43846191465854645 ,Valid is 0.3805323839187622\n",
      "覆盖最好的模型...\n",
      "epoch: 18\n",
      "The Model-Train-Time spent  0 min 10.85 s\n",
      "Accuracy : Train is 0.8645833333333333 , Valid is 0.8359375 ;  Loss : Train is  0.45460965236028034 ,Valid is 0.38946637511253357\n",
      "epoch: 19\n",
      "The Model-Train-Time spent  0 min 10.74 s\n",
      "Accuracy : Train is 0.8658854166666666 , Valid is 0.859375 ;  Loss : Train is  0.4376196910937627 ,Valid is 0.39534956216812134\n",
      "epoch: 20\n",
      "The Model-Train-Time spent  0 min 10.61 s\n",
      "Accuracy : Train is 0.8658854166666666 , Valid is 0.828125 ;  Loss : Train is  0.42126090824604034 ,Valid is 0.3938927948474884\n",
      "epoch: 21\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.8671875 , Valid is 0.8359375 ;  Loss : Train is  0.42151495814323425 ,Valid is 0.45667925477027893\n",
      "epoch: 22\n",
      "The Model-Train-Time spent  0 min 10.73 s\n",
      "Accuracy : Train is 0.8776041666666666 , Valid is 0.8359375 ;  Loss : Train is  0.42040664454301196 ,Valid is 0.441536009311676\n",
      "epoch: 23\n",
      "The Model-Train-Time spent  0 min 10.70 s\n",
      "Accuracy : Train is 0.87890625 , Valid is 0.859375 ;  Loss : Train is  0.4056798716386159 ,Valid is 0.3829135298728943\n",
      "epoch: 24\n",
      "The Model-Train-Time spent  0 min 10.74 s\n",
      "Accuracy : Train is 0.8723958333333333 , Valid is 0.890625 ;  Loss : Train is  0.39917046825091046 ,Valid is 0.3409005105495453\n",
      "覆盖最好的模型...\n",
      "epoch: 25\n",
      "The Model-Train-Time spent  0 min 10.63 s\n",
      "Accuracy : Train is 0.87109375 , Valid is 0.8671875 ;  Loss : Train is  0.40802665054798126 ,Valid is 0.3661577105522156\n",
      "epoch: 26\n",
      "The Model-Train-Time spent  0 min 10.92 s\n",
      "Accuracy : Train is 0.8684895833333333 , Valid is 0.859375 ;  Loss : Train is  0.40362458924452466 ,Valid is 0.36374929547309875\n",
      "epoch: 27\n",
      "The Model-Train-Time spent  0 min 10.89 s\n",
      "Accuracy : Train is 0.8645833333333333 , Valid is 0.8671875 ;  Loss : Train is  0.3960312306880951 ,Valid is 0.3331238925457001\n",
      "epoch: 28\n",
      "The Model-Train-Time spent  0 min 10.73 s\n",
      "Accuracy : Train is 0.8802083333333333 , Valid is 0.890625 ;  Loss : Train is  0.39435720940430957 ,Valid is 0.3491007089614868\n",
      "epoch: 29\n",
      "The Model-Train-Time spent  0 min 10.90 s\n",
      "Accuracy : Train is 0.8828125 , Valid is 0.875 ;  Loss : Train is  0.3938373476266861 ,Valid is 0.3433162569999695\n",
      "epoch: 30\n",
      "The Model-Train-Time spent  0 min 10.73 s\n",
      "Accuracy : Train is 0.8697916666666666 , Valid is 0.828125 ;  Loss : Train is  0.3945869753758113 ,Valid is 0.4053778052330017\n",
      "epoch: 31\n",
      "The Model-Train-Time spent  0 min 10.93 s\n",
      "Accuracy : Train is 0.8619791666666666 , Valid is 0.828125 ;  Loss : Train is  0.40962358315785724 ,Valid is 0.41356122493743896\n",
      "epoch: 32\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.8776041666666666 , Valid is 0.8984375 ;  Loss : Train is  0.38370708624521893 ,Valid is 0.30481457710266113\n",
      "覆盖最好的模型...\n",
      "epoch: 33\n",
      "The Model-Train-Time spent  0 min 11.52 s\n",
      "Accuracy : Train is 0.8671875 , Valid is 0.875 ;  Loss : Train is  0.402634859085083 ,Valid is 0.38437503576278687\n",
      "epoch: 34\n",
      "The Model-Train-Time spent  0 min 11.44 s\n",
      "Accuracy : Train is 0.88671875 , Valid is 0.90625 ;  Loss : Train is  0.3766568750143051 ,Valid is 0.3290398120880127\n",
      "覆盖最好的模型...\n",
      "epoch: 35\n",
      "The Model-Train-Time spent  0 min 11.52 s\n",
      "Accuracy : Train is 0.8645833333333333 , Valid is 0.890625 ;  Loss : Train is  0.3929353803396225 ,Valid is 0.3560521602630615\n",
      "epoch: 36\n",
      "The Model-Train-Time spent  0 min 11.40 s\n",
      "Accuracy : Train is 0.8776041666666666 , Valid is 0.84375 ;  Loss : Train is  0.38680022954940796 ,Valid is 0.41135212779045105\n",
      "epoch: 37\n",
      "The Model-Train-Time spent  0 min 11.42 s\n",
      "Accuracy : Train is 0.87890625 , Valid is 0.8515625 ;  Loss : Train is  0.37851522366205853 ,Valid is 0.39682719111442566\n",
      "epoch: 38\n",
      "The Model-Train-Time spent  0 min 11.26 s\n",
      "Accuracy : Train is 0.88671875 , Valid is 0.859375 ;  Loss : Train is  0.3758750408887863 ,Valid is 0.3922801613807678\n",
      "epoch: 39\n",
      "The Model-Train-Time spent  0 min 11.34 s\n",
      "Accuracy : Train is 0.8958333333333333 , Valid is 0.8984375 ;  Loss : Train is  0.37294573585192364 ,Valid is 0.30596843361854553\n",
      "epoch: 40\n",
      "The Model-Train-Time spent  0 min 11.44 s\n",
      "Accuracy : Train is 0.890625 , Valid is 0.8828125 ;  Loss : Train is  0.37133435408274335 ,Valid is 0.3922056257724762\n",
      "epoch: 41\n",
      "The Model-Train-Time spent  0 min 11.45 s\n",
      "Accuracy : Train is 0.8815104166666666 , Valid is 0.890625 ;  Loss : Train is  0.3628045817216237 ,Valid is 0.33272796869277954\n",
      "epoch: 42\n",
      "The Model-Train-Time spent  0 min 11.48 s\n",
      "Accuracy : Train is 0.8828125 , Valid is 0.8984375 ;  Loss : Train is  0.35505130887031555 ,Valid is 0.3796667456626892\n",
      "epoch: 43\n",
      "The Model-Train-Time spent  0 min 11.44 s\n",
      "Accuracy : Train is 0.87109375 , Valid is 0.8671875 ;  Loss : Train is  0.3704373687505722 ,Valid is 0.3912304639816284\n",
      "epoch: 44\n",
      "The Model-Train-Time spent  0 min 11.23 s\n",
      "Accuracy : Train is 0.8828125 , Valid is 0.8359375 ;  Loss : Train is  0.36271904905637103 ,Valid is 0.43382924795150757\n",
      "epoch: 45\n",
      "The Model-Train-Time spent  0 min 11.43 s\n",
      "Accuracy : Train is 0.8736979166666666 , Valid is 0.8828125 ;  Loss : Train is  0.3659590284029643 ,Valid is 0.3601182699203491\n",
      "epoch: 46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Model-Train-Time spent  0 min 11.44 s\n",
      "Accuracy : Train is 0.8880208333333333 , Valid is 0.890625 ;  Loss : Train is  0.36868780851364136 ,Valid is 0.2866174578666687\n",
      "epoch: 47\n",
      "The Model-Train-Time spent  0 min 11.13 s\n",
      "Accuracy : Train is 0.8802083333333333 , Valid is 0.875 ;  Loss : Train is  0.36482128004233044 ,Valid is 0.3401562571525574\n",
      "epoch: 48\n",
      "The Model-Train-Time spent  0 min 10.88 s\n",
      "Accuracy : Train is 0.8971354166666666 , Valid is 0.8828125 ;  Loss : Train is  0.35869719088077545 ,Valid is 0.3266463875770569\n",
      "epoch: 49\n",
      "The Model-Train-Time spent  0 min 10.83 s\n",
      "Accuracy : Train is 0.8841145833333333 , Valid is 0.8671875 ;  Loss : Train is  0.3650728911161423 ,Valid is 0.398722380399704\n",
      "epoch: 50\n",
      "The Model-Train-Time spent  0 min 10.79 s\n",
      "Accuracy : Train is 0.88671875 , Valid is 0.8984375 ;  Loss : Train is  0.3521818319956462 ,Valid is 0.3257908821105957\n",
      "epoch: 51\n",
      "The Model-Train-Time spent  0 min 10.75 s\n",
      "Accuracy : Train is 0.88671875 , Valid is 0.90625 ;  Loss : Train is  0.3459984560807546 ,Valid is 0.2605017423629761\n",
      "epoch: 52\n",
      "The Model-Train-Time spent  0 min 10.77 s\n",
      "Accuracy : Train is 0.8815104166666666 , Valid is 0.875 ;  Loss : Train is  0.3729535589615504 ,Valid is 0.34665027260780334\n",
      "epoch: 53\n",
      "The Model-Train-Time spent  0 min 10.66 s\n",
      "Accuracy : Train is 0.8854166666666666 , Valid is 0.9296875 ;  Loss : Train is  0.3556305418411891 ,Valid is 0.2827664613723755\n",
      "覆盖最好的模型...\n",
      "epoch: 54\n",
      "The Model-Train-Time spent  0 min 10.74 s\n",
      "Accuracy : Train is 0.8854166666666666 , Valid is 0.8359375 ;  Loss : Train is  0.3527064919471741 ,Valid is 0.43591830134391785\n",
      "epoch: 55\n",
      "The Model-Train-Time spent  0 min 10.80 s\n",
      "Accuracy : Train is 0.88671875 , Valid is 0.9140625 ;  Loss : Train is  0.36233627299467724 ,Valid is 0.32511720061302185\n",
      "epoch: 56\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.8802083333333333 , Valid is 0.9140625 ;  Loss : Train is  0.3643244355916977 ,Valid is 0.32554569840431213\n",
      "epoch: 57\n",
      "The Model-Train-Time spent  0 min 10.82 s\n",
      "Accuracy : Train is 0.88671875 , Valid is 0.875 ;  Loss : Train is  0.3479769478241603 ,Valid is 0.30755817890167236\n",
      "epoch: 58\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.875 , Valid is 0.90625 ;  Loss : Train is  0.36293362081050873 ,Valid is 0.3283582329750061\n",
      "epoch: 59\n",
      "The Model-Train-Time spent  0 min 10.78 s\n",
      "Accuracy : Train is 0.8893229166666666 , Valid is 0.890625 ;  Loss : Train is  0.35060710708300274 ,Valid is 0.3247184753417969\n",
      "epoch: 60\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.8828125 , Valid is 0.8984375 ;  Loss : Train is  0.358342245221138 ,Valid is 0.33550888299942017\n",
      "epoch: 61\n",
      "The Model-Train-Time spent  0 min 10.80 s\n",
      "Accuracy : Train is 0.8971354166666666 , Valid is 0.859375 ;  Loss : Train is  0.3508382538954417 ,Valid is 0.40519025921821594\n",
      "epoch: 62\n",
      "The Model-Train-Time spent  0 min 10.80 s\n",
      "Accuracy : Train is 0.8984375 , Valid is 0.8515625 ;  Loss : Train is  0.349428191781044 ,Valid is 0.40063807368278503\n",
      "epoch: 63\n",
      "The Model-Train-Time spent  0 min 10.79 s\n",
      "Accuracy : Train is 0.8919270833333333 , Valid is 0.8671875 ;  Loss : Train is  0.3537725359201431 ,Valid is 0.36048629879951477\n",
      "epoch: 64\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.8880208333333333 , Valid is 0.859375 ;  Loss : Train is  0.3551419625679652 ,Valid is 0.38586461544036865\n",
      "epoch: 65\n",
      "The Model-Train-Time spent  0 min 10.80 s\n",
      "Accuracy : Train is 0.8932291666666666 , Valid is 0.859375 ;  Loss : Train is  0.3415113886197408 ,Valid is 0.36719202995300293\n",
      "epoch: 66\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.8854166666666666 , Valid is 0.8515625 ;  Loss : Train is  0.35294143358866376 ,Valid is 0.407950758934021\n",
      "epoch: 67\n",
      "The Model-Train-Time spent  0 min 10.79 s\n",
      "Accuracy : Train is 0.8893229166666666 , Valid is 0.84375 ;  Loss : Train is  0.3536776254574458 ,Valid is 0.3761584460735321\n",
      "epoch: 68\n",
      "The Model-Train-Time spent  0 min 10.99 s\n",
      "Accuracy : Train is 0.8893229166666666 , Valid is 0.8203125 ;  Loss : Train is  0.3465655446052551 ,Valid is 0.4144822061061859\n",
      "epoch: 69\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.8828125 , Valid is 0.859375 ;  Loss : Train is  0.35068364938100177 ,Valid is 0.3902539014816284\n",
      "epoch: 70\n",
      "The Model-Train-Time spent  0 min 10.78 s\n",
      "Accuracy : Train is 0.8776041666666666 , Valid is 0.875 ;  Loss : Train is  0.34581538041432697 ,Valid is 0.4050721526145935\n",
      "epoch: 71\n",
      "The Model-Train-Time spent  0 min 10.92 s\n",
      "Accuracy : Train is 0.88671875 , Valid is 0.90625 ;  Loss : Train is  0.360317662358284 ,Valid is 0.3237038254737854\n",
      "epoch: 72\n",
      "The Model-Train-Time spent  0 min 10.83 s\n",
      "Accuracy : Train is 0.8893229166666666 , Valid is 0.90625 ;  Loss : Train is  0.35232821106910706 ,Valid is 0.26971435546875\n",
      "epoch: 73\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.8893229166666666 , Valid is 0.8984375 ;  Loss : Train is  0.347729633251826 ,Valid is 0.35810208320617676\n",
      "epoch: 74\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.8841145833333333 , Valid is 0.84375 ;  Loss : Train is  0.35336870948473614 ,Valid is 0.38121044635772705\n",
      "epoch: 75\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.8893229166666666 , Valid is 0.8671875 ;  Loss : Train is  0.3445697029431661 ,Valid is 0.37991514801979065\n",
      "epoch: 76\n",
      "The Model-Train-Time spent  0 min 10.84 s\n",
      "Accuracy : Train is 0.890625 , Valid is 0.8671875 ;  Loss : Train is  0.3479665120442708 ,Valid is 0.36793193221092224\n",
      "epoch: 77\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.890625 , Valid is 0.875 ;  Loss : Train is  0.35200661420822144 ,Valid is 0.3876492381095886\n",
      "epoch: 78\n",
      "The Model-Train-Time spent  0 min 10.80 s\n",
      "Accuracy : Train is 0.890625 , Valid is 0.859375 ;  Loss : Train is  0.3449566612641017 ,Valid is 0.3899385929107666\n",
      "epoch: 79\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.87890625 , Valid is 0.8828125 ;  Loss : Train is  0.36639953156312305 ,Valid is 0.355892539024353\n",
      "epoch: 80\n",
      "The Model-Train-Time spent  0 min 10.77 s\n",
      "Accuracy : Train is 0.8854166666666666 , Valid is 0.90625 ;  Loss : Train is  0.3485245903333028 ,Valid is 0.29910480976104736\n",
      "epoch: 81\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.89453125 , Valid is 0.8828125 ;  Loss : Train is  0.33756233255068463 ,Valid is 0.35522928833961487\n",
      "epoch: 82\n",
      "The Model-Train-Time spent  0 min 10.89 s\n",
      "Accuracy : Train is 0.8815104166666666 , Valid is 0.875 ;  Loss : Train is  0.3488447368144989 ,Valid is 0.3859770894050598\n",
      "epoch: 83\n",
      "The Model-Train-Time spent  0 min 10.89 s\n",
      "Accuracy : Train is 0.8932291666666666 , Valid is 0.875 ;  Loss : Train is  0.34670208891232807 ,Valid is 0.3445870578289032\n",
      "epoch: 84\n",
      "The Model-Train-Time spent  0 min 10.79 s\n",
      "Accuracy : Train is 0.8802083333333333 , Valid is 0.8984375 ;  Loss : Train is  0.35558881362279254 ,Valid is 0.337522029876709\n",
      "epoch: 85\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.8893229166666666 , Valid is 0.8515625 ;  Loss : Train is  0.3485473245382309 ,Valid is 0.429505854845047\n",
      "epoch: 86\n",
      "The Model-Train-Time spent  0 min 10.82 s\n",
      "Accuracy : Train is 0.89453125 , Valid is 0.8671875 ;  Loss : Train is  0.34591345489025116 ,Valid is 0.3255118429660797\n",
      "epoch: 87\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.8815104166666666 , Valid is 0.828125 ;  Loss : Train is  0.349960337082545 ,Valid is 0.4240332841873169\n",
      "epoch: 88\n",
      "The Model-Train-Time spent  0 min 10.89 s\n",
      "Accuracy : Train is 0.8932291666666666 , Valid is 0.859375 ;  Loss : Train is  0.3480229874451955 ,Valid is 0.36333099007606506\n",
      "epoch: 89\n",
      "The Model-Train-Time spent  0 min 10.82 s\n",
      "Accuracy : Train is 0.8815104166666666 , Valid is 0.9140625 ;  Loss : Train is  0.3528449833393097 ,Valid is 0.3440495431423187\n",
      "epoch: 90\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.890625 , Valid is 0.8359375 ;  Loss : Train is  0.34696908791859943 ,Valid is 0.39311090111732483\n",
      "epoch: 91\n",
      "The Model-Train-Time spent  0 min 10.91 s\n",
      "Accuracy : Train is 0.8932291666666666 , Valid is 0.90625 ;  Loss : Train is  0.34499624371528625 ,Valid is 0.2782851457595825\n",
      "epoch: 92\n",
      "The Model-Train-Time spent  0 min 10.79 s\n",
      "Accuracy : Train is 0.87890625 , Valid is 0.8984375 ;  Loss : Train is  0.3453921029965083 ,Valid is 0.2792995274066925\n",
      "epoch: 93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Model-Train-Time spent  0 min 10.80 s\n",
      "Accuracy : Train is 0.8854166666666666 , Valid is 0.8984375 ;  Loss : Train is  0.3488479753335317 ,Valid is 0.33453434705734253\n",
      "epoch: 94\n",
      "The Model-Train-Time spent  0 min 10.92 s\n",
      "Accuracy : Train is 0.890625 , Valid is 0.8671875 ;  Loss : Train is  0.34757956862449646 ,Valid is 0.3846011757850647\n",
      "epoch: 95\n",
      "The Model-Train-Time spent  0 min 10.78 s\n",
      "Accuracy : Train is 0.8854166666666666 , Valid is 0.8984375 ;  Loss : Train is  0.3597580095132192 ,Valid is 0.3486541509628296\n",
      "epoch: 96\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.8932291666666666 , Valid is 0.875 ;  Loss : Train is  0.3413452406724294 ,Valid is 0.35209447145462036\n",
      "epoch: 97\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.8880208333333333 , Valid is 0.890625 ;  Loss : Train is  0.3461432059605916 ,Valid is 0.36091986298561096\n",
      "epoch: 98\n",
      "The Model-Train-Time spent  0 min 10.80 s\n",
      "Accuracy : Train is 0.8815104166666666 , Valid is 0.875 ;  Loss : Train is  0.3495184729496638 ,Valid is 0.38911041617393494\n",
      "epoch: 99\n",
      "The Model-Train-Time spent  0 min 10.89 s\n",
      "Accuracy : Train is 0.8919270833333333 , Valid is 0.8828125 ;  Loss : Train is  0.3449411739905675 ,Valid is 0.35400649905204773\n",
      "epoch: 100\n",
      "The Model-Train-Time spent  0 min 10.88 s\n",
      "Accuracy : Train is 0.8828125 , Valid is 0.8515625 ;  Loss : Train is  0.35534081359704334 ,Valid is 0.39650654792785645\n",
      "epoch: 101\n",
      "The Model-Train-Time spent  0 min 10.79 s\n",
      "Accuracy : Train is 0.8841145833333333 , Valid is 0.859375 ;  Loss : Train is  0.3575419286886851 ,Valid is 0.39489930868148804\n",
      "epoch: 102\n",
      "The Model-Train-Time spent  0 min 10.86 s\n",
      "Accuracy : Train is 0.8919270833333333 , Valid is 0.875 ;  Loss : Train is  0.3458167264858882 ,Valid is 0.3432543873786926\n",
      "epoch: 103\n",
      "The Model-Train-Time spent  0 min 10.71 s\n",
      "Accuracy : Train is 0.8841145833333333 , Valid is 0.875 ;  Loss : Train is  0.35027193029721576 ,Valid is 0.3225063681602478\n",
      "epoch: 104\n",
      "The Model-Train-Time spent  0 min 10.74 s\n",
      "Accuracy : Train is 0.88671875 , Valid is 0.921875 ;  Loss : Train is  0.34845135112603504 ,Valid is 0.2758529782295227\n",
      "epoch: 105\n",
      "The Model-Train-Time spent  0 min 10.93 s\n",
      "Accuracy : Train is 0.8815104166666666 , Valid is 0.8984375 ;  Loss : Train is  0.34997281432151794 ,Valid is 0.3665268123149872\n",
      "epoch: 106\n",
      "The Model-Train-Time spent  0 min 10.87 s\n",
      "Accuracy : Train is 0.890625 , Valid is 0.8828125 ;  Loss : Train is  0.34299303591251373 ,Valid is 0.32830938696861267\n",
      "epoch: 107\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.8919270833333333 , Valid is 0.8671875 ;  Loss : Train is  0.34743012487888336 ,Valid is 0.3954440653324127\n",
      "epoch: 108\n",
      "The Model-Train-Time spent  0 min 10.80 s\n",
      "Accuracy : Train is 0.8971354166666666 , Valid is 0.8984375 ;  Loss : Train is  0.33055487275123596 ,Valid is 0.32424798607826233\n",
      "epoch: 109\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.88671875 , Valid is 0.90625 ;  Loss : Train is  0.3456006546815236 ,Valid is 0.3228018283843994\n",
      "epoch: 110\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.8828125 , Valid is 0.8984375 ;  Loss : Train is  0.3434249560038249 ,Valid is 0.2874148190021515\n",
      "epoch: 111\n",
      "The Model-Train-Time spent  0 min 10.90 s\n",
      "Accuracy : Train is 0.8919270833333333 , Valid is 0.90625 ;  Loss : Train is  0.3380833566188812 ,Valid is 0.31526434421539307\n",
      "epoch: 112\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.9010416666666666 , Valid is 0.8984375 ;  Loss : Train is  0.3356004108985265 ,Valid is 0.30880507826805115\n",
      "epoch: 113\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.9010416666666666 , Valid is 0.8671875 ;  Loss : Train is  0.3381250997384389 ,Valid is 0.39844197034835815\n",
      "epoch: 114\n",
      "The Model-Train-Time spent  0 min 10.89 s\n",
      "Accuracy : Train is 0.8880208333333333 , Valid is 0.8828125 ;  Loss : Train is  0.33388666808605194 ,Valid is 0.3716249465942383\n",
      "epoch: 115\n",
      "The Model-Train-Time spent  0 min 10.90 s\n",
      "Accuracy : Train is 0.8919270833333333 , Valid is 0.890625 ;  Loss : Train is  0.3293686757485072 ,Valid is 0.3456496596336365\n",
      "epoch: 116\n",
      "The Model-Train-Time spent  0 min 10.91 s\n",
      "Accuracy : Train is 0.8958333333333333 , Valid is 0.890625 ;  Loss : Train is  0.3403778870900472 ,Valid is 0.3014197051525116\n",
      "epoch: 117\n",
      "The Model-Train-Time spent  0 min 10.83 s\n",
      "Accuracy : Train is 0.88671875 , Valid is 0.890625 ;  Loss : Train is  0.3395761201779048 ,Valid is 0.32251137495040894\n",
      "epoch: 118\n",
      "The Model-Train-Time spent  0 min 10.80 s\n",
      "Accuracy : Train is 0.9036458333333333 , Valid is 0.859375 ;  Loss : Train is  0.3324836790561676 ,Valid is 0.4046122133731842\n",
      "epoch: 119\n",
      "The Model-Train-Time spent  0 min 10.78 s\n",
      "Accuracy : Train is 0.8893229166666666 , Valid is 0.875 ;  Loss : Train is  0.3276183009147644 ,Valid is 0.37348058819770813\n",
      "epoch: 120\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.8919270833333333 , Valid is 0.9140625 ;  Loss : Train is  0.33593231439590454 ,Valid is 0.32753831148147583\n",
      "epoch: 121\n",
      "The Model-Train-Time spent  0 min 10.78 s\n",
      "Accuracy : Train is 0.8984375 , Valid is 0.890625 ;  Loss : Train is  0.3395543396472931 ,Valid is 0.3192417621612549\n",
      "epoch: 122\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.88671875 , Valid is 0.9296875 ;  Loss : Train is  0.3354112356901169 ,Valid is 0.23307205736637115\n",
      "epoch: 123\n",
      "The Model-Train-Time spent  0 min 10.82 s\n",
      "Accuracy : Train is 0.8919270833333333 , Valid is 0.875 ;  Loss : Train is  0.32766243318716687 ,Valid is 0.35982468724250793\n",
      "epoch: 124\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.8971354166666666 , Valid is 0.9140625 ;  Loss : Train is  0.32501859962940216 ,Valid is 0.2945479452610016\n",
      "epoch: 125\n",
      "The Model-Train-Time spent  0 min 10.79 s\n",
      "Accuracy : Train is 0.8919270833333333 , Valid is 0.9140625 ;  Loss : Train is  0.32569869856039685 ,Valid is 0.2800164222717285\n",
      "epoch: 126\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.9036458333333333 , Valid is 0.859375 ;  Loss : Train is  0.32500723004341125 ,Valid is 0.35770711302757263\n",
      "epoch: 127\n",
      "The Model-Train-Time spent  0 min 10.77 s\n",
      "Accuracy : Train is 0.8997395833333333 , Valid is 0.9140625 ;  Loss : Train is  0.3413122544686 ,Valid is 0.3180803656578064\n",
      "epoch: 128\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.90234375 , Valid is 0.8515625 ;  Loss : Train is  0.3173994868993759 ,Valid is 0.4082261323928833\n",
      "epoch: 129\n",
      "The Model-Train-Time spent  0 min 10.92 s\n",
      "Accuracy : Train is 0.8932291666666666 , Valid is 0.9140625 ;  Loss : Train is  0.32901973525683087 ,Valid is 0.2702447772026062\n",
      "epoch: 130\n",
      "The Model-Train-Time spent  0 min 10.83 s\n",
      "Accuracy : Train is 0.90234375 , Valid is 0.8984375 ;  Loss : Train is  0.321816364924113 ,Valid is 0.31146034598350525\n",
      "epoch: 131\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.90234375 , Valid is 0.875 ;  Loss : Train is  0.3172116180260976 ,Valid is 0.3097679615020752\n",
      "epoch: 132\n",
      "The Model-Train-Time spent  0 min 10.90 s\n",
      "Accuracy : Train is 0.9010416666666666 , Valid is 0.8671875 ;  Loss : Train is  0.31044430037339527 ,Valid is 0.3851471245288849\n",
      "epoch: 133\n",
      "The Model-Train-Time spent  0 min 10.87 s\n",
      "Accuracy : Train is 0.9036458333333333 , Valid is 0.8671875 ;  Loss : Train is  0.30498046179612476 ,Valid is 0.3772103786468506\n",
      "epoch: 134\n",
      "The Model-Train-Time spent  0 min 10.84 s\n",
      "Accuracy : Train is 0.8971354166666666 , Valid is 0.890625 ;  Loss : Train is  0.32081857323646545 ,Valid is 0.3176382780075073\n",
      "epoch: 135\n",
      "The Model-Train-Time spent  0 min 10.92 s\n",
      "Accuracy : Train is 0.8997395833333333 , Valid is 0.8984375 ;  Loss : Train is  0.3164159009853999 ,Valid is 0.29545101523399353\n",
      "epoch: 136\n",
      "The Model-Train-Time spent  0 min 10.78 s\n",
      "Accuracy : Train is 0.9049479166666666 , Valid is 0.875 ;  Loss : Train is  0.3076302955547969 ,Valid is 0.38546374440193176\n",
      "epoch: 137\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.9010416666666666 , Valid is 0.8984375 ;  Loss : Train is  0.32055755456288654 ,Valid is 0.30580782890319824\n",
      "epoch: 138\n",
      "The Model-Train-Time spent  0 min 10.83 s\n",
      "Accuracy : Train is 0.89453125 , Valid is 0.890625 ;  Loss : Train is  0.31613875677188236 ,Valid is 0.3251854181289673\n",
      "epoch: 139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.9036458333333333 , Valid is 0.890625 ;  Loss : Train is  0.31103049715360004 ,Valid is 0.32292240858078003\n",
      "epoch: 140\n",
      "The Model-Train-Time spent  0 min 10.82 s\n",
      "Accuracy : Train is 0.9049479166666666 , Valid is 0.875 ;  Loss : Train is  0.30449581642945606 ,Valid is 0.3490264415740967\n",
      "epoch: 141\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.9075520833333333 , Valid is 0.890625 ;  Loss : Train is  0.3107470323642095 ,Valid is 0.3693159222602844\n",
      "epoch: 142\n",
      "The Model-Train-Time spent  0 min 10.68 s\n",
      "Accuracy : Train is 0.9140625 , Valid is 0.8984375 ;  Loss : Train is  0.2975005855162938 ,Valid is 0.35267776250839233\n",
      "epoch: 143\n",
      "The Model-Train-Time spent  0 min 10.71 s\n",
      "Accuracy : Train is 0.8997395833333333 , Valid is 0.8671875 ;  Loss : Train is  0.2973930438359578 ,Valid is 0.3414459228515625\n",
      "epoch: 144\n",
      "The Model-Train-Time spent  0 min 10.65 s\n",
      "Accuracy : Train is 0.91015625 , Valid is 0.875 ;  Loss : Train is  0.3124586244424184 ,Valid is 0.33218058943748474\n",
      "epoch: 145\n",
      "The Model-Train-Time spent  0 min 10.69 s\n",
      "Accuracy : Train is 0.9088541666666666 , Valid is 0.9375 ;  Loss : Train is  0.29791506628195447 ,Valid is 0.21820533275604248\n",
      "覆盖最好的模型...\n",
      "epoch: 146\n",
      "The Model-Train-Time spent  0 min 10.85 s\n",
      "Accuracy : Train is 0.9036458333333333 , Valid is 0.8515625 ;  Loss : Train is  0.29245265076557797 ,Valid is 0.3832886517047882\n",
      "epoch: 147\n",
      "The Model-Train-Time spent  0 min 10.84 s\n",
      "Accuracy : Train is 0.8997395833333333 , Valid is 0.90625 ;  Loss : Train is  0.3020881414413452 ,Valid is 0.29446348547935486\n",
      "epoch: 148\n",
      "The Model-Train-Time spent  0 min 10.85 s\n",
      "Accuracy : Train is 0.9010416666666666 , Valid is 0.859375 ;  Loss : Train is  0.3016601651906967 ,Valid is 0.4015626609325409\n",
      "epoch: 149\n",
      "The Model-Train-Time spent  0 min 10.71 s\n",
      "Accuracy : Train is 0.9127604166666666 , Valid is 0.890625 ;  Loss : Train is  0.3029719789822896 ,Valid is 0.284920871257782\n",
      "epoch: 150\n",
      "The Model-Train-Time spent  0 min 10.76 s\n",
      "Accuracy : Train is 0.8984375 , Valid is 0.875 ;  Loss : Train is  0.3000500947237015 ,Valid is 0.3233102560043335\n",
      "epoch: 151\n",
      "The Model-Train-Time spent  0 min 10.98 s\n",
      "Accuracy : Train is 0.90625 , Valid is 0.8828125 ;  Loss : Train is  0.2814522584279378 ,Valid is 0.37229499220848083\n",
      "epoch: 152\n",
      "The Model-Train-Time spent  0 min 10.96 s\n",
      "Accuracy : Train is 0.9127604166666666 , Valid is 0.8828125 ;  Loss : Train is  0.28319767117500305 ,Valid is 0.3579850196838379\n",
      "epoch: 153\n",
      "The Model-Train-Time spent  0 min 10.76 s\n",
      "Accuracy : Train is 0.90625 , Valid is 0.90625 ;  Loss : Train is  0.29507291316986084 ,Valid is 0.29331713914871216\n",
      "epoch: 154\n",
      "The Model-Train-Time spent  0 min 10.83 s\n",
      "Accuracy : Train is 0.91015625 , Valid is 0.90625 ;  Loss : Train is  0.2953177144130071 ,Valid is 0.3498695492744446\n",
      "epoch: 155\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.92578125 , Valid is 0.8828125 ;  Loss : Train is  0.28339824080467224 ,Valid is 0.3769133985042572\n",
      "epoch: 156\n",
      "The Model-Train-Time spent  0 min 10.73 s\n",
      "Accuracy : Train is 0.9192708333333333 , Valid is 0.8515625 ;  Loss : Train is  0.2814301997423172 ,Valid is 0.3740338087081909\n",
      "epoch: 157\n",
      "The Model-Train-Time spent  0 min 10.75 s\n",
      "Accuracy : Train is 0.92578125 , Valid is 0.859375 ;  Loss : Train is  0.2765248318513234 ,Valid is 0.3721899390220642\n",
      "epoch: 158\n",
      "The Model-Train-Time spent  0 min 10.78 s\n",
      "Accuracy : Train is 0.9231770833333333 , Valid is 0.890625 ;  Loss : Train is  0.2702394997080167 ,Valid is 0.30173608660697937\n",
      "epoch: 159\n",
      "The Model-Train-Time spent  0 min 10.90 s\n",
      "Accuracy : Train is 0.91015625 , Valid is 0.90625 ;  Loss : Train is  0.2832982540130615 ,Valid is 0.3384384512901306\n",
      "epoch: 160\n",
      "The Model-Train-Time spent  0 min 10.92 s\n",
      "Accuracy : Train is 0.9114583333333333 , Valid is 0.890625 ;  Loss : Train is  0.27286044259866077 ,Valid is 0.3345521092414856\n",
      "epoch: 161\n",
      "The Model-Train-Time spent  0 min 10.76 s\n",
      "Accuracy : Train is 0.9127604166666666 , Valid is 0.90625 ;  Loss : Train is  0.2696242406964302 ,Valid is 0.3296092748641968\n",
      "epoch: 162\n",
      "The Model-Train-Time spent  0 min 10.73 s\n",
      "Accuracy : Train is 0.921875 , Valid is 0.8671875 ;  Loss : Train is  0.2727636247873306 ,Valid is 0.3351200520992279\n",
      "epoch: 163\n",
      "The Model-Train-Time spent  0 min 10.67 s\n",
      "Accuracy : Train is 0.9166666666666666 , Valid is 0.890625 ;  Loss : Train is  0.2725735952456792 ,Valid is 0.3052073121070862\n",
      "epoch: 164\n",
      "The Model-Train-Time spent  0 min 10.84 s\n",
      "Accuracy : Train is 0.91796875 , Valid is 0.8984375 ;  Loss : Train is  0.28068118294080097 ,Valid is 0.29782044887542725\n",
      "epoch: 165\n",
      "The Model-Train-Time spent  0 min 10.93 s\n",
      "Accuracy : Train is 0.9244791666666666 , Valid is 0.84375 ;  Loss : Train is  0.2700880120197932 ,Valid is 0.3834417462348938\n",
      "epoch: 166\n",
      "The Model-Train-Time spent  0 min 10.73 s\n",
      "Accuracy : Train is 0.9153645833333333 , Valid is 0.8515625 ;  Loss : Train is  0.2631738930940628 ,Valid is 0.389401912689209\n",
      "epoch: 167\n",
      "The Model-Train-Time spent  0 min 10.67 s\n",
      "Accuracy : Train is 0.91796875 , Valid is 0.890625 ;  Loss : Train is  0.2681129475434621 ,Valid is 0.26628392934799194\n",
      "epoch: 168\n",
      "The Model-Train-Time spent  0 min 10.99 s\n",
      "Accuracy : Train is 0.91015625 , Valid is 0.8671875 ;  Loss : Train is  0.27571456631024677 ,Valid is 0.3801628053188324\n",
      "epoch: 169\n",
      "The Model-Train-Time spent  0 min 10.77 s\n",
      "Accuracy : Train is 0.9283854166666666 , Valid is 0.8984375 ;  Loss : Train is  0.2609728202223778 ,Valid is 0.2994418442249298\n",
      "epoch: 170\n",
      "The Model-Train-Time spent  0 min 10.66 s\n",
      "Accuracy : Train is 0.9244791666666666 , Valid is 0.875 ;  Loss : Train is  0.2632467746734619 ,Valid is 0.38848841190338135\n",
      "epoch: 171\n",
      "The Model-Train-Time spent  0 min 10.88 s\n",
      "Accuracy : Train is 0.9322916666666666 , Valid is 0.9453125 ;  Loss : Train is  0.25611966600020725 ,Valid is 0.2767435610294342\n",
      "覆盖最好的模型...\n",
      "epoch: 172\n",
      "The Model-Train-Time spent  0 min 10.76 s\n",
      "Accuracy : Train is 0.9192708333333333 , Valid is 0.8828125 ;  Loss : Train is  0.26623304188251495 ,Valid is 0.3794068694114685\n",
      "epoch: 173\n",
      "The Model-Train-Time spent  0 min 10.88 s\n",
      "Accuracy : Train is 0.9283854166666666 , Valid is 0.8828125 ;  Loss : Train is  0.25777938465277356 ,Valid is 0.35538989305496216\n",
      "epoch: 174\n",
      "The Model-Train-Time spent  0 min 10.57 s\n",
      "Accuracy : Train is 0.9283854166666666 , Valid is 0.8671875 ;  Loss : Train is  0.2602146541078885 ,Valid is 0.3625524044036865\n",
      "epoch: 175\n",
      "The Model-Train-Time spent  0 min 10.82 s\n",
      "Accuracy : Train is 0.9270833333333333 , Valid is 0.8984375 ;  Loss : Train is  0.2596542239189148 ,Valid is 0.3104454278945923\n",
      "epoch: 176\n",
      "The Model-Train-Time spent  0 min 10.82 s\n",
      "Accuracy : Train is 0.9322916666666666 , Valid is 0.90625 ;  Loss : Train is  0.2642356902360916 ,Valid is 0.26407894492149353\n",
      "epoch: 177\n",
      "The Model-Train-Time spent  0 min 10.64 s\n",
      "Accuracy : Train is 0.9283854166666666 , Valid is 0.8984375 ;  Loss : Train is  0.2645251552263896 ,Valid is 0.3236129879951477\n",
      "epoch: 178\n",
      "The Model-Train-Time spent  0 min 10.82 s\n",
      "Accuracy : Train is 0.9348958333333333 , Valid is 0.90625 ;  Loss : Train is  0.2621835668881734 ,Valid is 0.30252233147621155\n",
      "epoch: 179\n",
      "The Model-Train-Time spent  0 min 10.80 s\n",
      "Accuracy : Train is 0.9348958333333333 , Valid is 0.875 ;  Loss : Train is  0.2463433916370074 ,Valid is 0.3114200830459595\n",
      "epoch: 180\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.921875 , Valid is 0.875 ;  Loss : Train is  0.2601512223482132 ,Valid is 0.37802061438560486\n",
      "epoch: 181\n",
      "The Model-Train-Time spent  0 min 10.80 s\n",
      "Accuracy : Train is 0.9231770833333333 , Valid is 0.8828125 ;  Loss : Train is  0.26405521482229233 ,Valid is 0.33589160442352295\n",
      "epoch: 182\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.9283854166666666 , Valid is 0.8515625 ;  Loss : Train is  0.24874812612930933 ,Valid is 0.39170631766319275\n",
      "epoch: 183\n",
      "The Model-Train-Time spent  0 min 10.90 s\n",
      "Accuracy : Train is 0.921875 , Valid is 0.8515625 ;  Loss : Train is  0.2562764510512352 ,Valid is 0.3688853085041046\n",
      "epoch: 184\n",
      "The Model-Train-Time spent  0 min 10.80 s\n",
      "Accuracy : Train is 0.92578125 , Valid is 0.8828125 ;  Loss : Train is  0.24536747733751932 ,Valid is 0.29864954948425293\n",
      "epoch: 185\n",
      "The Model-Train-Time spent  0 min 10.83 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : Train is 0.9309895833333333 , Valid is 0.8828125 ;  Loss : Train is  0.24793036778767905 ,Valid is 0.3141951262950897\n",
      "epoch: 186\n",
      "The Model-Train-Time spent  0 min 10.86 s\n",
      "Accuracy : Train is 0.9244791666666666 , Valid is 0.8828125 ;  Loss : Train is  0.2647332052389781 ,Valid is 0.2938065826892853\n",
      "epoch: 187\n",
      "The Model-Train-Time spent  0 min 10.80 s\n",
      "Accuracy : Train is 0.9375 , Valid is 0.875 ;  Loss : Train is  0.24368350704511008 ,Valid is 0.32655853033065796\n",
      "epoch: 188\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.9296875 , Valid is 0.875 ;  Loss : Train is  0.2568406363328298 ,Valid is 0.27299824357032776\n",
      "epoch: 189\n",
      "The Model-Train-Time spent  0 min 10.78 s\n",
      "Accuracy : Train is 0.93359375 , Valid is 0.890625 ;  Loss : Train is  0.23538041363159815 ,Valid is 0.29823586344718933\n",
      "epoch: 190\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.9283854166666666 , Valid is 0.8984375 ;  Loss : Train is  0.25285593916972476 ,Valid is 0.27204757928848267\n",
      "epoch: 191\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.93359375 , Valid is 0.8828125 ;  Loss : Train is  0.2405346135298411 ,Valid is 0.32644131779670715\n",
      "epoch: 192\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.9388020833333333 , Valid is 0.8671875 ;  Loss : Train is  0.24933927257855734 ,Valid is 0.3171003758907318\n",
      "epoch: 193\n",
      "The Model-Train-Time spent  0 min 10.90 s\n",
      "Accuracy : Train is 0.9453125 , Valid is 0.8984375 ;  Loss : Train is  0.23225914935270944 ,Valid is 0.2749110162258148\n",
      "epoch: 194\n",
      "The Model-Train-Time spent  0 min 10.79 s\n",
      "Accuracy : Train is 0.9309895833333333 , Valid is 0.8984375 ;  Loss : Train is  0.24419350425402322 ,Valid is 0.28842002153396606\n",
      "epoch: 195\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.9401041666666666 , Valid is 0.890625 ;  Loss : Train is  0.23508403946956 ,Valid is 0.31721171736717224\n",
      "epoch: 196\n",
      "The Model-Train-Time spent  0 min 10.77 s\n",
      "Accuracy : Train is 0.9388020833333333 , Valid is 0.875 ;  Loss : Train is  0.24960835029681525 ,Valid is 0.34794625639915466\n",
      "epoch: 197\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.9427083333333333 , Valid is 0.90625 ;  Loss : Train is  0.23739731311798096 ,Valid is 0.2777411639690399\n",
      "epoch: 198\n",
      "The Model-Train-Time spent  0 min 10.82 s\n",
      "Accuracy : Train is 0.9401041666666666 , Valid is 0.890625 ;  Loss : Train is  0.23739910374085108 ,Valid is 0.2766966223716736\n",
      "epoch: 199\n",
      "The Model-Train-Time spent  0 min 10.81 s\n",
      "Accuracy : Train is 0.9401041666666666 , Valid is 0.8671875 ;  Loss : Train is  0.23635249584913254 ,Valid is 0.34926867485046387\n"
     ]
    }
   ],
   "source": [
    "#关于AMP自动精度求解，我也并不是很熟悉，只能使用官方给的实例进行照葫芦画瓢。\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "torch.cuda.empty_cache()\n",
    "for epoch in range(D_epoch, epochs):\n",
    "    time_one = time.time()                         #标记训练开始时间戳\n",
    "    train_acc1 = 0.0\n",
    "    train_loss1 = 0.0\n",
    "    train_acc = 0.0\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    val_acc = 0.0\n",
    "    val_loss = 0.0\n",
    "    number = 0\n",
    "    model.train()\n",
    "    print(\"epoch:\",epoch)\n",
    "\n",
    "    for batchidx , (x,label,division_list,pn_list) in enumerate(data_train):\n",
    "        x = x.to(device)\n",
    "        label = label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            y1 = model(x,division_list,pn_list)\n",
    "            loss = criteon(y1,label)  + mcml_loss(y1,label)\n",
    "        _, preds1 = torch.max(F.softmax(y1,dim=1), 1)\n",
    "        #AMP优化\n",
    "        scaler.scale(loss).backward()\n",
    "#         loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm = 5, norm_type=2)  #梯度剪裁\n",
    "        scaler.step(optimizer)\n",
    "#         optimizer.step()\n",
    "        scaler.update()\n",
    "        train_loss1 += loss.item()*batch_size\n",
    "        train_acc1 += torch.sum(preds1 == label.data).double()\n",
    "        number = number + 1\n",
    "    time_two = time.time()             #标记训练结束时间戳\n",
    "    #输出训练一轮所需时间，用于分析对比\n",
    "    print(\"The Model-Train-Time spent  %d min %.2f s\"%((time_two-time_one)//60,(time_two-time_one)%60))\n",
    "    #计算训练时候的平均损失和平均准确率\n",
    "    train_loss = train_loss1 / (number*batch_size)\n",
    "    train_acc = train_acc1 / (number*batch_size)\n",
    "    #计算测试时候的平均损失和平均准确率\n",
    "    val_acc, val_loss = evalute_(model, data_val)\n",
    "    \n",
    "    train_acc = train_acc.cpu()\n",
    "    val_acc = val_acc.cpu()\n",
    "    print('Accuracy : Train is {} , Valid is {} ;  Loss : Train is  {} ,Valid is {}'.format(train_acc, val_acc, train_loss , val_loss))\n",
    "    #如果你不需要训练以及验证的准确率和损失值，你可以注释这下面的两行，它们不是非必须的，理论上只存在于汇报和论文中\n",
    "    dataframe = pd.DataFrame(columns = [epoch,train_acc,train_loss,val_acc, val_loss])\n",
    "    dataframe.to_csv(data_csv_path,line_terminator=\"\\n\",mode='a',index=False,sep=',')\n",
    "    if val_acc > best_acc:\n",
    "        print(\"覆盖最好的模型...\")\n",
    "        best_acc = val_acc \n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'best_acc':best_acc\n",
    "        }\n",
    "        torch.save(checkpoint,model_save_path)\n",
    "#     time_three = time.time() \n",
    "#     print(\"测试花费时间\",time_three-time_two)\n",
    "    scheduler.step()  #动态学习率更新 \n",
    "#如果你不是非必须，我建议你尽量不要使用n折交叉验证，使用数据增强可能效果更优于它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
