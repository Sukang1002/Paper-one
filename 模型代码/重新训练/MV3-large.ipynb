{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57e525aa",
   "metadata": {},
   "source": [
    "author:sukang  \n",
    "time:2022-02-17  \n",
    "reference:https://github.com/xiaolai-sqlai/mobilenetv3  \n",
    "title:MV3-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba903702",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-15T07:08:08.645571Z",
     "start_time": "2022-04-15T07:08:06.995746Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch.cuda.amp import autocast \n",
    "from torch.cuda.amp import GradScaler\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchsummary import summary\n",
    "import time\n",
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a33eb25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-15T07:08:08.660812Z",
     "start_time": "2022-04-15T07:08:08.646562Z"
    }
   },
   "outputs": [],
   "source": [
    "#优化参数\n",
    "#cudnn参数  会额外增加一部分显存\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "930472c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-15T07:08:08.676632Z",
     "start_time": "2022-04-15T07:08:08.662806Z"
    }
   },
   "outputs": [],
   "source": [
    "#保存训练数据和模型\n",
    "data_csv_path = \"D:\\\\OneModel\\\\MV3_large_optimizer_Cos.csv\"   #修改此处文件名 \n",
    "model_save_path = \"D:\\\\OneModel\\\\MV3_large_optimizer_Cos.pkl\"  #修改此处文件名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e438d8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-15T07:08:08.692502Z",
     "start_time": "2022-04-15T07:08:08.678538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 200 learning_rate: 0.0005 batch_size: 128\n"
     ]
    }
   ],
   "source": [
    "#设置数据集路径\n",
    "train_path = \"D:\\\\Dataset\\\\RAF-DB\\\\train\"\n",
    "val_path = \"D:\\\\Dataset\\\\RAF-DB\\\\test\"\n",
    "#模型批次大小\n",
    "batch_size = 128\n",
    "resume = True\n",
    "#动态学习率，学习率和循环次数增加\n",
    "lr = 5e-4 \n",
    "epochs = 200\n",
    "D_epoch = 0 \n",
    "best_acc  = 0\n",
    "print(\"epochs:\",epochs,\"learning_rate:\",lr,\"batch_size:\",batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fe86687",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-15T07:08:08.724439Z",
     "start_time": "2022-04-15T07:08:08.693500Z"
    },
    "code_folding": [
     12,
     29
    ]
   },
   "outputs": [],
   "source": [
    "class hswish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        out = x * F.relu6(x + 3, inplace=True) / 6\n",
    "        return out\n",
    "\n",
    "\n",
    "class hsigmoid(nn.Module):\n",
    "    def forward(self, x):\n",
    "        out = F.relu6(x + 3, inplace=True) / 6\n",
    "        return out\n",
    "\n",
    "\n",
    "class SeModule(nn.Module):\n",
    "    def __init__(self, in_size, reduction=4):\n",
    "        super(SeModule, self).__init__()\n",
    "        self.se = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(in_size, in_size // reduction, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(in_size // reduction),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_size // reduction, in_size, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(in_size),\n",
    "            hsigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.se(x)\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    '''expand + depthwise + pointwise'''\n",
    "    def __init__(self, kernel_size, in_size, expand_size, out_size, nolinear, semodule, stride):\n",
    "        super(Block, self).__init__()\n",
    "        self.stride = stride\n",
    "        self.se = semodule\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_size, expand_size, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(expand_size)\n",
    "        self.nolinear1 = nolinear\n",
    "        self.conv2 = nn.Conv2d(expand_size, expand_size, kernel_size=kernel_size, stride=stride, padding=kernel_size//2, groups=expand_size, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(expand_size)\n",
    "        self.nolinear2 = nolinear\n",
    "        self.conv3 = nn.Conv2d(expand_size, out_size, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_size)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride == 1 and in_size != out_size:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_size, out_size, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "                nn.BatchNorm2d(out_size),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.nolinear1(self.bn1(self.conv1(x)))\n",
    "        out = self.nolinear2(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        if self.se != None:\n",
    "            out = self.se(out)\n",
    "        out = out + self.shortcut(x) if self.stride==1 else out\n",
    "        return out\n",
    "\n",
    "\n",
    "class MobileNetV3_Large(nn.Module):\n",
    "    def __init__(self, num_classes=7):\n",
    "        super(MobileNetV3_Large, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.hs1 = hswish()\n",
    "\n",
    "        self.bneck = nn.Sequential(\n",
    "            Block(3, 16, 16, 16, nn.ReLU(inplace=True), None, 1),\n",
    "            Block(3, 16, 64, 24, nn.ReLU(inplace=True), None, 2),\n",
    "            Block(3, 24, 72, 24, nn.ReLU(inplace=True), None, 1),\n",
    "            Block(5, 24, 72, 40, nn.ReLU(inplace=True), SeModule(40), 2),\n",
    "            Block(5, 40, 120, 40, nn.ReLU(inplace=True), SeModule(40), 1),\n",
    "            Block(5, 40, 120, 40, nn.ReLU(inplace=True), SeModule(40), 1),\n",
    "            Block(3, 40, 240, 80, hswish(), None, 2),\n",
    "            Block(3, 80, 200, 80, hswish(), None, 1),\n",
    "            Block(3, 80, 184, 80, hswish(), None, 1),\n",
    "            Block(3, 80, 184, 80, hswish(), None, 1),\n",
    "            Block(3, 80, 480, 112, hswish(), SeModule(112), 1),\n",
    "            Block(3, 112, 672, 112, hswish(), SeModule(112), 1),\n",
    "            Block(5, 112, 672, 160, hswish(), SeModule(160), 1),\n",
    "            Block(5, 160, 672, 160, hswish(), SeModule(160), 2),\n",
    "            Block(5, 160, 960, 160, hswish(), SeModule(160), 1),\n",
    "        )\n",
    "\n",
    "\n",
    "        self.conv2 = nn.Conv2d(160, 960, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(960)\n",
    "        self.hs2 = hswish()\n",
    "        self.apool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.linear3 = nn.Linear(960, 1280)\n",
    "        self.bn3 = nn.BatchNorm1d(1280)\n",
    "        self.hs3 = hswish()\n",
    "        self.linear4 = nn.Linear(1280, num_classes)\n",
    "        self.init_params()\n",
    "\n",
    "    def init_params(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                init.constant_(m.weight, 1)\n",
    "                init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                init.normal_(m.weight, std=0.001)\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.hs1(self.bn1(self.conv1(x)))\n",
    "        out = self.bneck(out)\n",
    "        out = self.hs2(self.bn2(self.conv2(out)))\n",
    "        out = self.apool(out)\n",
    "        out =  torch.flatten(out, 1)\n",
    "        out = self.hs3(self.bn3(self.linear3(out)))\n",
    "        out = self.linear4(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c7568b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-15T07:08:08.755866Z",
     "start_time": "2022-04-15T07:08:08.725414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU\n",
      "divice is  cuda:0\n"
     ]
    }
   ],
   "source": [
    "#设备选取\n",
    "flag = torch.cuda.is_available()\n",
    "if flag:\n",
    "    print(\"GPU\")\n",
    "else:\n",
    "    print(\"CPU\")\n",
    "ngpu = 1\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "#查看显卡名称\n",
    "#torch.cuda.get_device_name()\n",
    "print(\"divice is \", device)\n",
    "\n",
    "#数据预处理（建议提前resize，减少每次资源的损失）放大到112x112 ，随机水平翻转\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "#增加不同种transform，预测集中去除随机翻转\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2bdd1a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-15T07:08:08.834683Z",
     "start_time": "2022-04-15T07:08:08.756864Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 12271\n",
      "    Root location: D:\\Dataset\\RAF-DB\\train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=None)\n",
      "               RandomHorizontalFlip(p=0.5)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "           )\n",
      "Dataset ImageFolder\n",
      "    Number of datapoints: 3068\n",
      "    Root location: D:\\Dataset\\RAF-DB\\test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=None)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "           )\n",
      "['Anger', 'Disgust', 'Fear', 'Happiness', 'Neutral', 'Sadness', 'Surprise']\n",
      "{'Anger': 0, 'Disgust': 1, 'Fear': 2, 'Happiness': 3, 'Neutral': 4, 'Sadness': 5, 'Surprise': 6}\n",
      "\n",
      "['Anger', 'Disgust', 'Fear', 'Happiness', 'Neutral', 'Sadness', 'Surprise']\n",
      "{'Anger': 0, 'Disgust': 1, 'Fear': 2, 'Happiness': 3, 'Neutral': 4, 'Sadness': 5, 'Surprise': 6}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#使用torchvision.datasets.ImageFolder读取数据集指定train和test文件夹\n",
    "train_data = torchvision.datasets.ImageFolder(train_path, transform=train_transform)\n",
    "#drop_last舍弃未满一个批次的数据        num_workers工作区一般设置为GPU个数的4倍\n",
    "data0_train = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True,num_workers=4)\n",
    "print(train_data)  #输出训练集相关\n",
    "val_data = torchvision.datasets.ImageFolder(val_path, transform=val_transform)\n",
    "data1_val = DataLoader(val_data, batch_size=batch_size, shuffle=True,drop_last=True,num_workers=4)\n",
    "print(val_data)  #输出测试集相关\n",
    "\n",
    "print(train_data.classes)  #根据分的文件夹的名字来确定的类别\n",
    "print(train_data.class_to_idx) #按顺序为这些类别定义索引为0,1...\n",
    "print()\n",
    "print(val_data.classes)\n",
    "print(val_data.class_to_idx)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4768c1a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-15T07:08:12.609861Z",
     "start_time": "2022-04-15T07:08:08.835652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1        [128, 16, 112, 112]             432\n",
      "       BatchNorm2d-2        [128, 16, 112, 112]              32\n",
      "            hswish-3        [128, 16, 112, 112]               0\n",
      "            Conv2d-4        [128, 16, 112, 112]             256\n",
      "       BatchNorm2d-5        [128, 16, 112, 112]              32\n",
      "              ReLU-6        [128, 16, 112, 112]               0\n",
      "            Conv2d-7        [128, 16, 112, 112]             144\n",
      "       BatchNorm2d-8        [128, 16, 112, 112]              32\n",
      "              ReLU-9        [128, 16, 112, 112]               0\n",
      "           Conv2d-10        [128, 16, 112, 112]             256\n",
      "      BatchNorm2d-11        [128, 16, 112, 112]              32\n",
      "            Block-12        [128, 16, 112, 112]               0\n",
      "           Conv2d-13        [128, 64, 112, 112]           1,024\n",
      "      BatchNorm2d-14        [128, 64, 112, 112]             128\n",
      "             ReLU-15        [128, 64, 112, 112]               0\n",
      "           Conv2d-16          [128, 64, 56, 56]             576\n",
      "      BatchNorm2d-17          [128, 64, 56, 56]             128\n",
      "             ReLU-18          [128, 64, 56, 56]               0\n",
      "           Conv2d-19          [128, 24, 56, 56]           1,536\n",
      "      BatchNorm2d-20          [128, 24, 56, 56]              48\n",
      "            Block-21          [128, 24, 56, 56]               0\n",
      "           Conv2d-22          [128, 72, 56, 56]           1,728\n",
      "      BatchNorm2d-23          [128, 72, 56, 56]             144\n",
      "             ReLU-24          [128, 72, 56, 56]               0\n",
      "           Conv2d-25          [128, 72, 56, 56]             648\n",
      "      BatchNorm2d-26          [128, 72, 56, 56]             144\n",
      "             ReLU-27          [128, 72, 56, 56]               0\n",
      "           Conv2d-28          [128, 24, 56, 56]           1,728\n",
      "      BatchNorm2d-29          [128, 24, 56, 56]              48\n",
      "            Block-30          [128, 24, 56, 56]               0\n",
      "           Conv2d-31          [128, 72, 56, 56]           1,728\n",
      "      BatchNorm2d-32          [128, 72, 56, 56]             144\n",
      "             ReLU-33          [128, 72, 56, 56]               0\n",
      "           Conv2d-34          [128, 72, 28, 28]           1,800\n",
      "      BatchNorm2d-35          [128, 72, 28, 28]             144\n",
      "             ReLU-36          [128, 72, 28, 28]               0\n",
      "           Conv2d-37          [128, 40, 28, 28]           2,880\n",
      "      BatchNorm2d-38          [128, 40, 28, 28]              80\n",
      "AdaptiveAvgPool2d-39            [128, 40, 1, 1]               0\n",
      "           Conv2d-40            [128, 10, 1, 1]             400\n",
      "      BatchNorm2d-41            [128, 10, 1, 1]              20\n",
      "             ReLU-42            [128, 10, 1, 1]               0\n",
      "           Conv2d-43            [128, 40, 1, 1]             400\n",
      "      BatchNorm2d-44            [128, 40, 1, 1]              80\n",
      "         hsigmoid-45            [128, 40, 1, 1]               0\n",
      "         SeModule-46          [128, 40, 28, 28]               0\n",
      "            Block-47          [128, 40, 28, 28]               0\n",
      "           Conv2d-48         [128, 120, 28, 28]           4,800\n",
      "      BatchNorm2d-49         [128, 120, 28, 28]             240\n",
      "             ReLU-50         [128, 120, 28, 28]               0\n",
      "           Conv2d-51         [128, 120, 28, 28]           3,000\n",
      "      BatchNorm2d-52         [128, 120, 28, 28]             240\n",
      "             ReLU-53         [128, 120, 28, 28]               0\n",
      "           Conv2d-54          [128, 40, 28, 28]           4,800\n",
      "      BatchNorm2d-55          [128, 40, 28, 28]              80\n",
      "AdaptiveAvgPool2d-56            [128, 40, 1, 1]               0\n",
      "           Conv2d-57            [128, 10, 1, 1]             400\n",
      "      BatchNorm2d-58            [128, 10, 1, 1]              20\n",
      "             ReLU-59            [128, 10, 1, 1]               0\n",
      "           Conv2d-60            [128, 40, 1, 1]             400\n",
      "      BatchNorm2d-61            [128, 40, 1, 1]              80\n",
      "         hsigmoid-62            [128, 40, 1, 1]               0\n",
      "         SeModule-63          [128, 40, 28, 28]               0\n",
      "            Block-64          [128, 40, 28, 28]               0\n",
      "           Conv2d-65         [128, 120, 28, 28]           4,800\n",
      "      BatchNorm2d-66         [128, 120, 28, 28]             240\n",
      "             ReLU-67         [128, 120, 28, 28]               0\n",
      "           Conv2d-68         [128, 120, 28, 28]           3,000\n",
      "      BatchNorm2d-69         [128, 120, 28, 28]             240\n",
      "             ReLU-70         [128, 120, 28, 28]               0\n",
      "           Conv2d-71          [128, 40, 28, 28]           4,800\n",
      "      BatchNorm2d-72          [128, 40, 28, 28]              80\n",
      "AdaptiveAvgPool2d-73            [128, 40, 1, 1]               0\n",
      "           Conv2d-74            [128, 10, 1, 1]             400\n",
      "      BatchNorm2d-75            [128, 10, 1, 1]              20\n",
      "             ReLU-76            [128, 10, 1, 1]               0\n",
      "           Conv2d-77            [128, 40, 1, 1]             400\n",
      "      BatchNorm2d-78            [128, 40, 1, 1]              80\n",
      "         hsigmoid-79            [128, 40, 1, 1]               0\n",
      "         SeModule-80          [128, 40, 28, 28]               0\n",
      "            Block-81          [128, 40, 28, 28]               0\n",
      "           Conv2d-82         [128, 240, 28, 28]           9,600\n",
      "      BatchNorm2d-83         [128, 240, 28, 28]             480\n",
      "           hswish-84         [128, 240, 28, 28]               0\n",
      "           Conv2d-85         [128, 240, 14, 14]           2,160\n",
      "      BatchNorm2d-86         [128, 240, 14, 14]             480\n",
      "           hswish-87         [128, 240, 14, 14]               0\n",
      "           Conv2d-88          [128, 80, 14, 14]          19,200\n",
      "      BatchNorm2d-89          [128, 80, 14, 14]             160\n",
      "            Block-90          [128, 80, 14, 14]               0\n",
      "           Conv2d-91         [128, 200, 14, 14]          16,000\n",
      "      BatchNorm2d-92         [128, 200, 14, 14]             400\n",
      "           hswish-93         [128, 200, 14, 14]               0\n",
      "           Conv2d-94         [128, 200, 14, 14]           1,800\n",
      "      BatchNorm2d-95         [128, 200, 14, 14]             400\n",
      "           hswish-96         [128, 200, 14, 14]               0\n",
      "           Conv2d-97          [128, 80, 14, 14]          16,000\n",
      "      BatchNorm2d-98          [128, 80, 14, 14]             160\n",
      "            Block-99          [128, 80, 14, 14]               0\n",
      "          Conv2d-100         [128, 184, 14, 14]          14,720\n",
      "     BatchNorm2d-101         [128, 184, 14, 14]             368\n",
      "          hswish-102         [128, 184, 14, 14]               0\n",
      "          Conv2d-103         [128, 184, 14, 14]           1,656\n",
      "     BatchNorm2d-104         [128, 184, 14, 14]             368\n",
      "          hswish-105         [128, 184, 14, 14]               0\n",
      "          Conv2d-106          [128, 80, 14, 14]          14,720\n",
      "     BatchNorm2d-107          [128, 80, 14, 14]             160\n",
      "           Block-108          [128, 80, 14, 14]               0\n",
      "          Conv2d-109         [128, 184, 14, 14]          14,720\n",
      "     BatchNorm2d-110         [128, 184, 14, 14]             368\n",
      "          hswish-111         [128, 184, 14, 14]               0\n",
      "          Conv2d-112         [128, 184, 14, 14]           1,656\n",
      "     BatchNorm2d-113         [128, 184, 14, 14]             368\n",
      "          hswish-114         [128, 184, 14, 14]               0\n",
      "          Conv2d-115          [128, 80, 14, 14]          14,720\n",
      "     BatchNorm2d-116          [128, 80, 14, 14]             160\n",
      "           Block-117          [128, 80, 14, 14]               0\n",
      "          Conv2d-118         [128, 480, 14, 14]          38,400\n",
      "     BatchNorm2d-119         [128, 480, 14, 14]             960\n",
      "          hswish-120         [128, 480, 14, 14]               0\n",
      "          Conv2d-121         [128, 480, 14, 14]           4,320\n",
      "     BatchNorm2d-122         [128, 480, 14, 14]             960\n",
      "          hswish-123         [128, 480, 14, 14]               0\n",
      "          Conv2d-124         [128, 112, 14, 14]          53,760\n",
      "     BatchNorm2d-125         [128, 112, 14, 14]             224\n",
      "AdaptiveAvgPool2d-126           [128, 112, 1, 1]               0\n",
      "          Conv2d-127            [128, 28, 1, 1]           3,136\n",
      "     BatchNorm2d-128            [128, 28, 1, 1]              56\n",
      "            ReLU-129            [128, 28, 1, 1]               0\n",
      "          Conv2d-130           [128, 112, 1, 1]           3,136\n",
      "     BatchNorm2d-131           [128, 112, 1, 1]             224\n",
      "        hsigmoid-132           [128, 112, 1, 1]               0\n",
      "        SeModule-133         [128, 112, 14, 14]               0\n",
      "          Conv2d-134         [128, 112, 14, 14]           8,960\n",
      "     BatchNorm2d-135         [128, 112, 14, 14]             224\n",
      "           Block-136         [128, 112, 14, 14]               0\n",
      "          Conv2d-137         [128, 672, 14, 14]          75,264\n",
      "     BatchNorm2d-138         [128, 672, 14, 14]           1,344\n",
      "          hswish-139         [128, 672, 14, 14]               0\n",
      "          Conv2d-140         [128, 672, 14, 14]           6,048\n",
      "     BatchNorm2d-141         [128, 672, 14, 14]           1,344\n",
      "          hswish-142         [128, 672, 14, 14]               0\n",
      "          Conv2d-143         [128, 112, 14, 14]          75,264\n",
      "     BatchNorm2d-144         [128, 112, 14, 14]             224\n",
      "AdaptiveAvgPool2d-145           [128, 112, 1, 1]               0\n",
      "          Conv2d-146            [128, 28, 1, 1]           3,136\n",
      "     BatchNorm2d-147            [128, 28, 1, 1]              56\n",
      "            ReLU-148            [128, 28, 1, 1]               0\n",
      "          Conv2d-149           [128, 112, 1, 1]           3,136\n",
      "     BatchNorm2d-150           [128, 112, 1, 1]             224\n",
      "        hsigmoid-151           [128, 112, 1, 1]               0\n",
      "        SeModule-152         [128, 112, 14, 14]               0\n",
      "           Block-153         [128, 112, 14, 14]               0\n",
      "          Conv2d-154         [128, 672, 14, 14]          75,264\n",
      "     BatchNorm2d-155         [128, 672, 14, 14]           1,344\n",
      "          hswish-156         [128, 672, 14, 14]               0\n",
      "          Conv2d-157         [128, 672, 14, 14]          16,800\n",
      "     BatchNorm2d-158         [128, 672, 14, 14]           1,344\n",
      "          hswish-159         [128, 672, 14, 14]               0\n",
      "          Conv2d-160         [128, 160, 14, 14]         107,520\n",
      "     BatchNorm2d-161         [128, 160, 14, 14]             320\n",
      "AdaptiveAvgPool2d-162           [128, 160, 1, 1]               0\n",
      "          Conv2d-163            [128, 40, 1, 1]           6,400\n",
      "     BatchNorm2d-164            [128, 40, 1, 1]              80\n",
      "            ReLU-165            [128, 40, 1, 1]               0\n",
      "          Conv2d-166           [128, 160, 1, 1]           6,400\n",
      "     BatchNorm2d-167           [128, 160, 1, 1]             320\n",
      "        hsigmoid-168           [128, 160, 1, 1]               0\n",
      "        SeModule-169         [128, 160, 14, 14]               0\n",
      "          Conv2d-170         [128, 160, 14, 14]          17,920\n",
      "     BatchNorm2d-171         [128, 160, 14, 14]             320\n",
      "           Block-172         [128, 160, 14, 14]               0\n",
      "          Conv2d-173         [128, 672, 14, 14]         107,520\n",
      "     BatchNorm2d-174         [128, 672, 14, 14]           1,344\n",
      "          hswish-175         [128, 672, 14, 14]               0\n",
      "          Conv2d-176           [128, 672, 7, 7]          16,800\n",
      "     BatchNorm2d-177           [128, 672, 7, 7]           1,344\n",
      "          hswish-178           [128, 672, 7, 7]               0\n",
      "          Conv2d-179           [128, 160, 7, 7]         107,520\n",
      "     BatchNorm2d-180           [128, 160, 7, 7]             320\n",
      "AdaptiveAvgPool2d-181           [128, 160, 1, 1]               0\n",
      "          Conv2d-182            [128, 40, 1, 1]           6,400\n",
      "     BatchNorm2d-183            [128, 40, 1, 1]              80\n",
      "            ReLU-184            [128, 40, 1, 1]               0\n",
      "          Conv2d-185           [128, 160, 1, 1]           6,400\n",
      "     BatchNorm2d-186           [128, 160, 1, 1]             320\n",
      "        hsigmoid-187           [128, 160, 1, 1]               0\n",
      "        SeModule-188           [128, 160, 7, 7]               0\n",
      "           Block-189           [128, 160, 7, 7]               0\n",
      "          Conv2d-190           [128, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-191           [128, 960, 7, 7]           1,920\n",
      "          hswish-192           [128, 960, 7, 7]               0\n",
      "          Conv2d-193           [128, 960, 7, 7]          24,000\n",
      "     BatchNorm2d-194           [128, 960, 7, 7]           1,920\n",
      "          hswish-195           [128, 960, 7, 7]               0\n",
      "          Conv2d-196           [128, 160, 7, 7]         153,600\n",
      "     BatchNorm2d-197           [128, 160, 7, 7]             320\n",
      "AdaptiveAvgPool2d-198           [128, 160, 1, 1]               0\n",
      "          Conv2d-199            [128, 40, 1, 1]           6,400\n",
      "     BatchNorm2d-200            [128, 40, 1, 1]              80\n",
      "            ReLU-201            [128, 40, 1, 1]               0\n",
      "          Conv2d-202           [128, 160, 1, 1]           6,400\n",
      "     BatchNorm2d-203           [128, 160, 1, 1]             320\n",
      "        hsigmoid-204           [128, 160, 1, 1]               0\n",
      "        SeModule-205           [128, 160, 7, 7]               0\n",
      "           Block-206           [128, 160, 7, 7]               0\n",
      "          Conv2d-207           [128, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-208           [128, 960, 7, 7]           1,920\n",
      "          hswish-209           [128, 960, 7, 7]               0\n",
      "AdaptiveAvgPool2d-210           [128, 960, 1, 1]               0\n",
      "          Linear-211                [128, 1280]       1,230,080\n",
      "     BatchNorm1d-212                [128, 1280]           2,560\n",
      "          hswish-213                [128, 1280]               0\n",
      "          Linear-214                   [128, 7]           8,967\n",
      "================================================================\n",
      "Total params: 2,683,883\n",
      "Trainable params: 2,683,883\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 73.50\n",
      "Forward/backward pass size (MB): 14336.42\n",
      "Params size (MB): 10.24\n",
      "Estimated Total Size (MB): 14420.16\n",
      "----------------------------------------------------------------\n",
      "\n",
      "=================model summary ======================\n"
     ]
    }
   ],
   "source": [
    "#to(device)将模型加入GPU中加速计算\n",
    "model = MobileNetV3_Large().to(device)\n",
    "#设置优化器  \n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "#设置损失函数MobileNetV3_Large\n",
    "criteon = nn.CrossEntropyLoss().to(device)\n",
    "#余弦衰减学习率\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=80, eta_min=0,verbose = True)\n",
    "#形如TensorFlow中的summary函数输出模型参数\n",
    "summary(model, input_size=[(3, 224, 224)], batch_size=batch_size, device=\"cuda\")\n",
    "print()\n",
    "\n",
    "#torch官方输出参数，目测不是很好\n",
    "print(\"=================model summary ======================\")\n",
    "# print(\"VGG16 Net:\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2222f73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-15T07:08:12.625818Z",
     "start_time": "2022-04-15T07:08:12.610857Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "执行结束\n"
     ]
    }
   ],
   "source": [
    "#测试函数\n",
    "def evalute_(model,val_loader):\n",
    "    model.eval()\n",
    "    test_loss2 = 0.0\n",
    "    test_corrects2 = 0.0\n",
    "    number = 0\n",
    "    for batchidx, (x, label) in enumerate(val_loader):\n",
    "#         print(number)\n",
    "    #torch.cuda.empty_cache()  #清除非必要GPU缓存，但是我建议不要在训练中使用此句，这可能会损失你相当多的时间\n",
    "        number = number + 1\n",
    "        x, label = x.to(device), label.to(device)\n",
    "        #测试函数中加入no_grad()，如果不加会增加计算和显存\n",
    "        with torch.no_grad():\n",
    "            y1 = model(x)\n",
    "            #虽然可以直接使用max函数，但是我建议在y1的比较重你最好使用F.softmax(y1,dim=1)，这样可能会有更好的效果，我在训练中使用了它\n",
    "            _, preds1 = torch.max(F.softmax(y1,dim=1), 1)\n",
    "            loss = criteon(y1, label)  \n",
    "            \n",
    "            test_loss2 += loss.item()*batch_size\n",
    "            test_corrects2 += torch.sum(preds1 == label.data)\n",
    "    #由于使用了最后一次抛弃，我不能使用全部测试集作为分母，这样会使最后的准确率变小\n",
    "    test_loss1 = test_loss2 / (number*batch_size)\n",
    "    test_acc1 = test_corrects2.double() / (number*batch_size)\n",
    "#     print(\"TestDataset loss is \", test_loss1,\"TestDataset accuracy is \",test_acc1)\n",
    "    return test_acc1, test_loss1\n",
    "print(\"执行结束\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6eeb5f58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-15T09:33:28.044914Z",
     "start_time": "2022-04-15T07:08:12.627812Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "The Model-Train-Time spent  0 min 36.28 s\n",
      "Accuracy : Train is 0.3748355263157895 , Valid is 0.382133152173913 ;  Loss : Train is  1.662230832953202 ,Valid is 1.6441715126452239\n",
      "覆盖最好的模型...\n",
      "Adjusting learning rate of group 0 to 4.9981e-04.\n",
      "epoch: 1\n",
      "The Model-Train-Time spent  0 min 32.54 s\n",
      "Accuracy : Train is 0.4463815789473684 , Valid is 0.48335597826086957 ;  Loss : Train is  1.478145066060518 ,Valid is 1.521660918774812\n",
      "覆盖最好的模型...\n",
      "Adjusting learning rate of group 0 to 4.9923e-04.\n",
      "epoch: 2\n",
      "The Model-Train-Time spent  0 min 32.52 s\n",
      "Accuracy : Train is 0.5305098684210526 , Valid is 0.5784646739130435 ;  Loss : Train is  1.2996336635790373 ,Valid is 1.1902399529581484\n",
      "覆盖最好的模型...\n",
      "Adjusting learning rate of group 0 to 4.9827e-04.\n",
      "epoch: 3\n",
      "The Model-Train-Time spent  0 min 31.85 s\n",
      "Accuracy : Train is 0.5986842105263158 , Valid is 0.6188858695652174 ;  Loss : Train is  1.1117090658137674 ,Valid is 1.0806081994720127\n",
      "覆盖最好的模型...\n",
      "Adjusting learning rate of group 0 to 4.9692e-04.\n",
      "epoch: 4\n",
      "The Model-Train-Time spent  0 min 31.75 s\n",
      "Accuracy : Train is 0.6523026315789473 , Valid is 0.6311141304347826 ;  Loss : Train is  0.9586861779815272 ,Valid is 1.0392790488574817\n",
      "覆盖最好的模型...\n",
      "Adjusting learning rate of group 0 to 4.9520e-04.\n",
      "epoch: 5\n",
      "The Model-Train-Time spent  0 min 32.62 s\n",
      "Accuracy : Train is 0.6931743421052632 , Valid is 0.6759510869565217 ;  Loss : Train is  0.850109494987287 ,Valid is 0.9058909208878226\n",
      "覆盖最好的模型...\n",
      "Adjusting learning rate of group 0 to 4.9309e-04.\n",
      "epoch: 6\n",
      "The Model-Train-Time spent  0 min 32.29 s\n",
      "Accuracy : Train is 0.7143092105263158 , Valid is 0.6226222826086957 ;  Loss : Train is  0.7927233514032865 ,Valid is 1.068305826705435\n",
      "Adjusting learning rate of group 0 to 4.9061e-04.\n",
      "epoch: 7\n",
      "The Model-Train-Time spent  0 min 32.00 s\n",
      "Accuracy : Train is 0.7289473684210526 , Valid is 0.6637228260869565 ;  Loss : Train is  0.7597269597806429 ,Valid is 0.9656740712082904\n",
      "Adjusting learning rate of group 0 to 4.8776e-04.\n",
      "epoch: 8\n",
      "The Model-Train-Time spent  0 min 31.84 s\n",
      "Accuracy : Train is 0.7661184210526316 , Valid is 0.6820652173913043 ;  Loss : Train is  0.6555215029340041 ,Valid is 0.904019806696021\n",
      "覆盖最好的模型...\n",
      "Adjusting learning rate of group 0 to 4.8455e-04.\n",
      "epoch: 9\n",
      "The Model-Train-Time spent  0 min 31.91 s\n",
      "Accuracy : Train is 0.8000822368421052 , Valid is 0.7245244565217391 ;  Loss : Train is  0.5646087442573748 ,Valid is 0.812862823838773\n",
      "覆盖最好的模型...\n",
      "Adjusting learning rate of group 0 to 4.8097e-04.\n",
      "epoch: 10\n",
      "The Model-Train-Time spent  0 min 33.09 s\n",
      "Accuracy : Train is 0.8337993421052632 , Valid is 0.7163722826086957 ;  Loss : Train is  0.4717938680397837 ,Valid is 0.8861665207406749\n",
      "Adjusting learning rate of group 0 to 4.7704e-04.\n",
      "epoch: 11\n",
      "The Model-Train-Time spent  0 min 31.86 s\n",
      "Accuracy : Train is 0.8563322368421052 , Valid is 0.7194293478260869 ;  Loss : Train is  0.40315206850829877 ,Valid is 0.9534656405448914\n",
      "Adjusting learning rate of group 0 to 4.7275e-04.\n",
      "epoch: 12\n",
      "The Model-Train-Time spent  0 min 31.94 s\n",
      "Accuracy : Train is 0.8792763157894736 , Valid is 0.7126358695652174 ;  Loss : Train is  0.3421370576871069 ,Valid is 0.9548417277958082\n",
      "Adjusting learning rate of group 0 to 4.6812e-04.\n",
      "epoch: 13\n",
      "The Model-Train-Time spent  0 min 32.55 s\n",
      "Accuracy : Train is 0.9021381578947368 , Valid is 0.7197690217391304 ;  Loss : Train is  0.28476069600958576 ,Valid is 1.0021918338278066\n",
      "Adjusting learning rate of group 0 to 4.6316e-04.\n",
      "epoch: 14\n",
      "The Model-Train-Time spent  0 min 33.83 s\n",
      "Accuracy : Train is 0.9185855263157895 , Valid is 0.717391304347826 ;  Loss : Train is  0.2377856838075738 ,Valid is 1.042825354182202\n",
      "Adjusting learning rate of group 0 to 4.5787e-04.\n",
      "epoch: 15\n",
      "The Model-Train-Time spent  0 min 32.20 s\n",
      "Accuracy : Train is 0.9249999999999999 , Valid is 0.7309782608695652 ;  Loss : Train is  0.21130110707722213 ,Valid is 1.058847225230673\n",
      "覆盖最好的模型...\n",
      "Adjusting learning rate of group 0 to 4.5225e-04.\n",
      "epoch: 16\n",
      "The Model-Train-Time spent  0 min 32.11 s\n",
      "Accuracy : Train is 0.9384868421052631 , Valid is 0.7306385869565217 ;  Loss : Train is  0.18365586337290313 ,Valid is 1.0726915286934895\n",
      "Adjusting learning rate of group 0 to 4.4633e-04.\n",
      "epoch: 17\n",
      "The Model-Train-Time spent  0 min 31.92 s\n",
      "Accuracy : Train is 0.9426809210526316 , Valid is 0.7347146739130435 ;  Loss : Train is  0.1612948996456046 ,Valid is 1.1977856703426526\n",
      "覆盖最好的模型...\n",
      "Adjusting learning rate of group 0 to 4.4010e-04.\n",
      "epoch: 18\n",
      "The Model-Train-Time spent  0 min 31.74 s\n",
      "Accuracy : Train is 0.9471217105263158 , Valid is 0.7309782608695652 ;  Loss : Train is  0.1540437089769464 ,Valid is 1.1883145674415256\n",
      "Adjusting learning rate of group 0 to 4.3358e-04.\n",
      "epoch: 19\n",
      "The Model-Train-Time spent  0 min 31.94 s\n",
      "Accuracy : Train is 0.9532894736842105 , Valid is 0.7404891304347826 ;  Loss : Train is  0.1313114128614727 ,Valid is 1.1526274810666624\n",
      "覆盖最好的模型...\n",
      "Adjusting learning rate of group 0 to 4.2678e-04.\n",
      "epoch: 20\n",
      "The Model-Train-Time spent  0 min 31.94 s\n",
      "Accuracy : Train is 0.9595394736842106 , Valid is 0.741508152173913 ;  Loss : Train is  0.11398394233302066 ,Valid is 1.2278864280037258\n",
      "覆盖最好的模型...\n",
      "Adjusting learning rate of group 0 to 4.1970e-04.\n",
      "epoch: 21\n",
      "The Model-Train-Time spent  0 min 31.82 s\n",
      "Accuracy : Train is 0.9648026315789473 , Valid is 0.7228260869565217 ;  Loss : Train is  0.10205814320790141 ,Valid is 1.2054335708203523\n",
      "Adjusting learning rate of group 0 to 4.1236e-04.\n",
      "epoch: 22\n",
      "The Model-Train-Time spent  0 min 31.91 s\n",
      "Accuracy : Train is 0.9679276315789473 , Valid is 0.7238451086956521 ;  Loss : Train is  0.09554827027022839 ,Valid is 1.2925190018570942\n",
      "Adjusting learning rate of group 0 to 4.0477e-04.\n",
      "epoch: 23\n",
      "The Model-Train-Time spent  0 min 31.95 s\n",
      "Accuracy : Train is 0.9702302631578947 , Valid is 0.7401494565217391 ;  Loss : Train is  0.08631024613584343 ,Valid is 1.312006986659506\n",
      "Adjusting learning rate of group 0 to 3.9695e-04.\n",
      "epoch: 24\n",
      "The Model-Train-Time spent  0 min 31.93 s\n",
      "Accuracy : Train is 0.9723684210526315 , Valid is 0.741508152173913 ;  Loss : Train is  0.07790322483174111 ,Valid is 1.2896860786106275\n",
      "Adjusting learning rate of group 0 to 3.8889e-04.\n",
      "epoch: 25\n",
      "The Model-Train-Time spent  0 min 31.91 s\n",
      "Accuracy : Train is 0.9734375 , Valid is 0.7384510869565217 ;  Loss : Train is  0.07861368511068194 ,Valid is 1.3055910286696062\n",
      "Adjusting learning rate of group 0 to 3.8062e-04.\n",
      "epoch: 26\n",
      "The Model-Train-Time spent  0 min 31.91 s\n",
      "Accuracy : Train is 0.9779605263157894 , Valid is 0.7370923913043478 ;  Loss : Train is  0.06448883367212195 ,Valid is 1.334980669228927\n",
      "Adjusting learning rate of group 0 to 3.7216e-04.\n",
      "epoch: 27\n",
      "The Model-Train-Time spent  0 min 32.43 s\n",
      "Accuracy : Train is 0.9799342105263158 , Valid is 0.7557744565217391 ;  Loss : Train is  0.06044151456536431 ,Valid is 1.3187973473383032\n",
      "覆盖最好的模型...\n",
      "Adjusting learning rate of group 0 to 3.6350e-04.\n",
      "epoch: 28\n",
      "The Model-Train-Time spent  0 min 31.83 s\n",
      "Accuracy : Train is 0.9929276315789474 , Valid is 0.7646059782608695 ;  Loss : Train is  0.0228808080581458 ,Valid is 1.330289267975351\n",
      "覆盖最好的模型...\n",
      "Adjusting learning rate of group 0 to 3.5466e-04.\n",
      "epoch: 29\n",
      "The Model-Train-Time spent  0 min 32.52 s\n",
      "Accuracy : Train is 0.9949013157894737 , Valid is 0.7472826086956521 ;  Loss : Train is  0.018250167556107044 ,Valid is 1.4811944028605586\n",
      "Adjusting learning rate of group 0 to 3.4567e-04.\n",
      "epoch: 30\n",
      "The Model-Train-Time spent  0 min 32.46 s\n",
      "Accuracy : Train is 0.9953124999999999 , Valid is 0.7516983695652174 ;  Loss : Train is  0.016180901043117046 ,Valid is 1.4835591419883396\n",
      "Adjusting learning rate of group 0 to 3.3653e-04.\n",
      "epoch: 31\n",
      "The Model-Train-Time spent  0 min 31.88 s\n",
      "Accuracy : Train is 0.9946546052631579 , Valid is 0.7503396739130435 ;  Loss : Train is  0.01610287565149759 ,Valid is 1.5407037164853967\n",
      "Adjusting learning rate of group 0 to 3.2725e-04.\n",
      "epoch: 32\n",
      "The Model-Train-Time spent  0 min 31.99 s\n",
      "Accuracy : Train is 0.9954769736842105 , Valid is 0.7554347826086957 ;  Loss : Train is  0.012921390015827983 ,Valid is 1.6254434637401416\n",
      "Adjusting learning rate of group 0 to 3.1786e-04.\n",
      "epoch: 33\n",
      "The Model-Train-Time spent  0 min 31.84 s\n",
      "Accuracy : Train is 0.9948190789473684 , Valid is 0.756453804347826 ;  Loss : Train is  0.015124190657546647 ,Valid is 1.6557676196098328\n",
      "Adjusting learning rate of group 0 to 3.0836e-04.\n",
      "epoch: 34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Model-Train-Time spent  0 min 31.92 s\n",
      "Accuracy : Train is 0.9963815789473685 , Valid is 0.7503396739130435 ;  Loss : Train is  0.011565654734639745 ,Valid is 1.703002473582392\n",
      "Adjusting learning rate of group 0 to 2.9877e-04.\n",
      "epoch: 35\n",
      "The Model-Train-Time spent  0 min 31.83 s\n",
      "Accuracy : Train is 0.9952302631578948 , Valid is 0.75 ;  Loss : Train is  0.013010877968841478 ,Valid is 1.6823941210041875\n",
      "Adjusting learning rate of group 0 to 2.8911e-04.\n",
      "epoch: 36\n",
      "The Model-Train-Time spent  0 min 32.52 s\n",
      "Accuracy : Train is 0.9961348684210526 , Valid is 0.749320652173913 ;  Loss : Train is  0.011830421056794493 ,Valid is 1.766458537267602\n",
      "Adjusting learning rate of group 0 to 2.7938e-04.\n",
      "epoch: 37\n",
      "The Model-Train-Time spent  0 min 31.94 s\n",
      "Accuracy : Train is 0.9855263157894737 , Valid is 0.7398097826086957 ;  Loss : Train is  0.04288273174315691 ,Valid is 1.8536696434020996\n",
      "Adjusting learning rate of group 0 to 2.6961e-04.\n",
      "epoch: 38\n",
      "The Model-Train-Time spent  0 min 31.91 s\n",
      "Accuracy : Train is 0.9845394736842105 , Valid is 0.7381114130434783 ;  Loss : Train is  0.046477092371175165 ,Valid is 1.8369538006575212\n",
      "Adjusting learning rate of group 0 to 2.5981e-04.\n",
      "epoch: 39\n",
      "The Model-Train-Time spent  0 min 32.45 s\n",
      "Accuracy : Train is 0.9845394736842105 , Valid is 0.7445652173913043 ;  Loss : Train is  0.04822627747137295 ,Valid is 1.7432208631349646\n",
      "Adjusting learning rate of group 0 to 2.5000e-04.\n",
      "epoch: 40\n",
      "The Model-Train-Time spent  0 min 32.96 s\n",
      "Accuracy : Train is 0.9877467105263158 , Valid is 0.75 ;  Loss : Train is  0.03464095530737388 ,Valid is 1.6918680408726567\n",
      "Adjusting learning rate of group 0 to 2.4019e-04.\n",
      "epoch: 41\n",
      "The Model-Train-Time spent  0 min 32.46 s\n",
      "Accuracy : Train is 0.9884046052631579 , Valid is 0.7367527173913043 ;  Loss : Train is  0.03205601937676731 ,Valid is 1.8570428050082664\n",
      "Adjusting learning rate of group 0 to 2.3039e-04.\n",
      "epoch: 42\n",
      "The Model-Train-Time spent  0 min 31.82 s\n",
      "Accuracy : Train is 0.9761513157894737 , Valid is 0.7394701086956521 ;  Loss : Train is  0.06788354964044534 ,Valid is 1.7198830946632053\n",
      "Adjusting learning rate of group 0 to 2.2062e-04.\n",
      "epoch: 43\n",
      "The Model-Train-Time spent  0 min 31.92 s\n",
      "Accuracy : Train is 0.9789473684210526 , Valid is 0.7323369565217391 ;  Loss : Train is  0.06694109256526357 ,Valid is 1.7045821780743806\n",
      "Adjusting learning rate of group 0 to 2.1089e-04.\n",
      "epoch: 44\n",
      "The Model-Train-Time spent  0 min 31.83 s\n",
      "Accuracy : Train is 0.9820723684210526 , Valid is 0.7520380434782609 ;  Loss : Train is  0.05281522243626808 ,Valid is 1.6218907677608987\n",
      "Adjusting learning rate of group 0 to 2.0123e-04.\n",
      "epoch: 45\n",
      "The Model-Train-Time spent  0 min 31.94 s\n",
      "Accuracy : Train is 0.9855263157894737 , Valid is 0.75 ;  Loss : Train is  0.0399302744257607 ,Valid is 1.639745453129644\n",
      "Adjusting learning rate of group 0 to 1.9164e-04.\n",
      "epoch: 46\n",
      "The Model-Train-Time spent  0 min 31.83 s\n",
      "Accuracy : Train is 0.9887335526315789 , Valid is 0.740828804347826 ;  Loss : Train is  0.03391161101233018 ,Valid is 1.6517003826473071\n",
      "Adjusting learning rate of group 0 to 1.8214e-04.\n",
      "epoch: 47\n",
      "The Model-Train-Time spent  0 min 31.85 s\n",
      "Accuracy : Train is 0.9926809210526315 , Valid is 0.7510190217391304 ;  Loss : Train is  0.020997868723383075 ,Valid is 1.672917946525242\n",
      "Adjusting learning rate of group 0 to 1.7275e-04.\n",
      "epoch: 48\n",
      "The Model-Train-Time spent  0 min 31.91 s\n",
      "Accuracy : Train is 0.9938322368421052 , Valid is 0.7466032608695652 ;  Loss : Train is  0.01715455191504014 ,Valid is 1.8091313113336978\n",
      "Adjusting learning rate of group 0 to 1.6347e-04.\n",
      "epoch: 49\n",
      "The Model-Train-Time spent  0 min 31.82 s\n",
      "Accuracy : Train is 0.9956414473684211 , Valid is 0.751358695652174 ;  Loss : Train is  0.012319838618369479 ,Valid is 1.7896736652954766\n",
      "Adjusting learning rate of group 0 to 1.5433e-04.\n",
      "epoch: 50\n",
      "The Model-Train-Time spent  0 min 31.93 s\n",
      "Accuracy : Train is 0.9965460526315789 , Valid is 0.7554347826086957 ;  Loss : Train is  0.01119299931941848 ,Valid is 1.9220788271530815\n",
      "Adjusting learning rate of group 0 to 1.4534e-04.\n",
      "epoch: 51\n",
      "The Model-Train-Time spent  0 min 31.88 s\n",
      "Accuracy : Train is 0.9962993421052632 , Valid is 0.7459239130434783 ;  Loss : Train is  0.01076991564937328 ,Valid is 1.9840432198151299\n",
      "Adjusting learning rate of group 0 to 1.3650e-04.\n",
      "epoch: 52\n",
      "The Model-Train-Time spent  0 min 31.79 s\n",
      "Accuracy : Train is 0.9977796052631579 , Valid is 0.7601902173913043 ;  Loss : Train is  0.008112861216068268 ,Valid is 2.013202703517416\n",
      "Adjusting learning rate of group 0 to 1.2784e-04.\n",
      "epoch: 53\n",
      "The Model-Train-Time spent  0 min 31.85 s\n",
      "Accuracy : Train is 0.997203947368421 , Valid is 0.75 ;  Loss : Train is  0.008012602850794793 ,Valid is 2.0239332810692163\n",
      "Adjusting learning rate of group 0 to 1.1938e-04.\n",
      "epoch: 54\n",
      "The Model-Train-Time spent  0 min 31.88 s\n",
      "Accuracy : Train is 0.9983552631578947 , Valid is 0.7676630434782609 ;  Loss : Train is  0.005220524613794527 ,Valid is 2.0705389613690586\n",
      "覆盖最好的模型...\n",
      "Adjusting learning rate of group 0 to 1.1111e-04.\n",
      "epoch: 55\n",
      "The Model-Train-Time spent  0 min 31.70 s\n",
      "Accuracy : Train is 0.9983552631578947 , Valid is 0.764945652173913 ;  Loss : Train is  0.006106148944481423 ,Valid is 2.1306831525719683\n",
      "Adjusting learning rate of group 0 to 1.0305e-04.\n",
      "epoch: 56\n",
      "The Model-Train-Time spent  0 min 31.82 s\n",
      "Accuracy : Train is 0.9990953947368421 , Valid is 0.757133152173913 ;  Loss : Train is  0.003502996432545938 ,Valid is 2.1869391254756763\n",
      "Adjusting learning rate of group 0 to 9.5227e-05.\n",
      "epoch: 57\n",
      "The Model-Train-Time spent  0 min 31.87 s\n",
      "Accuracy : Train is 0.9994243421052631 , Valid is 0.7686820652173912 ;  Loss : Train is  0.0013869208430773332 ,Valid is 2.238978194153827\n",
      "覆盖最好的模型...\n",
      "Adjusting learning rate of group 0 to 8.7638e-05.\n",
      "epoch: 58\n",
      "The Model-Train-Time spent  0 min 31.99 s\n",
      "Accuracy : Train is 0.999671052631579 , Valid is 0.7646059782608695 ;  Loss : Train is  0.0011448559890452185 ,Valid is 2.270553169043168\n",
      "Adjusting learning rate of group 0 to 8.0300e-05.\n",
      "epoch: 59\n",
      "The Model-Train-Time spent  0 min 31.99 s\n",
      "Accuracy : Train is 0.999671052631579 , Valid is 0.764266304347826 ;  Loss : Train is  0.000978625673604639 ,Valid is 2.3544401967007182\n",
      "Adjusting learning rate of group 0 to 7.3223e-05.\n",
      "epoch: 60\n",
      "The Model-Train-Time spent  0 min 31.95 s\n",
      "Accuracy : Train is 0.9994243421052631 , Valid is 0.7629076086956521 ;  Loss : Train is  0.0020045780821850425 ,Valid is 2.4217162754224693\n",
      "Adjusting learning rate of group 0 to 6.6419e-05.\n",
      "epoch: 61\n",
      "The Model-Train-Time spent  0 min 31.89 s\n",
      "Accuracy : Train is 0.9999177631578947 , Valid is 0.7615489130434783 ;  Loss : Train is  0.00037379007982580285 ,Valid is 2.460815139438795\n",
      "Adjusting learning rate of group 0 to 5.9899e-05.\n",
      "epoch: 62\n",
      "The Model-Train-Time spent  0 min 31.93 s\n",
      "Accuracy : Train is 0.9997532894736841 , Valid is 0.7707201086956521 ;  Loss : Train is  0.0005338969591416811 ,Valid is 2.4968952044196753\n",
      "覆盖最好的模型...\n",
      "Adjusting learning rate of group 0 to 5.3671e-05.\n",
      "epoch: 63\n",
      "The Model-Train-Time spent  0 min 31.96 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7635869565217391 ;  Loss : Train is  8.921995759010315e-05 ,Valid is 2.4867746259855186\n",
      "Adjusting learning rate of group 0 to 4.7746e-05.\n",
      "epoch: 64\n",
      "The Model-Train-Time spent  0 min 31.75 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7666440217391304 ;  Loss : Train is  5.5014694991864655e-05 ,Valid is 2.4930475846580835\n",
      "Adjusting learning rate of group 0 to 4.2133e-05.\n",
      "epoch: 65\n",
      "The Model-Train-Time spent  0 min 31.88 s\n",
      "Accuracy : Train is 0.9999177631578947 , Valid is 0.7652853260869565 ;  Loss : Train is  0.0002144070734318934 ,Valid is 2.5265935503918193\n",
      "Adjusting learning rate of group 0 to 3.6840e-05.\n",
      "epoch: 66\n",
      "The Model-Train-Time spent  0 min 32.47 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7673233695652174 ;  Loss : Train is  5.5440681937493776e-05 ,Valid is 2.5169964925102564\n",
      "Adjusting learning rate of group 0 to 3.1876e-05.\n",
      "epoch: 67\n",
      "The Model-Train-Time spent  0 min 32.56 s\n",
      "Accuracy : Train is 0.9999177631578947 , Valid is 0.7697010869565217 ;  Loss : Train is  0.0008955404848644608 ,Valid is 2.540959487790647\n",
      "Adjusting learning rate of group 0 to 2.7248e-05.\n",
      "epoch: 68\n",
      "The Model-Train-Time spent  0 min 31.70 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7690217391304348 ;  Loss : Train is  9.730350422231774e-06 ,Valid is 2.538603057032046\n",
      "Adjusting learning rate of group 0 to 2.2964e-05.\n",
      "epoch: 69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Model-Train-Time spent  0 min 33.31 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.764266304347826 ;  Loss : Train is  5.833629126611509e-05 ,Valid is 2.575608922087628\n",
      "Adjusting learning rate of group 0 to 1.9030e-05.\n",
      "epoch: 70\n",
      "The Model-Train-Time spent  0 min 32.52 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7734375 ;  Loss : Train is  9.81513018670835e-06 ,Valid is 2.5231981173805567\n",
      "覆盖最好的模型...\n",
      "Adjusting learning rate of group 0 to 1.5452e-05.\n",
      "epoch: 71\n",
      "The Model-Train-Time spent  0 min 32.61 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7703804347826086 ;  Loss : Train is  4.039126399316286e-05 ,Valid is 2.6046608530956767\n",
      "Adjusting learning rate of group 0 to 1.2236e-05.\n",
      "epoch: 72\n",
      "The Model-Train-Time spent  0 min 32.53 s\n",
      "Accuracy : Train is 0.9998355263157894 , Valid is 0.7693614130434783 ;  Loss : Train is  0.0004246450862602184 ,Valid is 2.5477193023847495\n",
      "Adjusting learning rate of group 0 to 9.3862e-06.\n",
      "epoch: 73\n",
      "The Model-Train-Time spent  0 min 32.65 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7680027173913043 ;  Loss : Train is  7.2402389425980414e-06 ,Valid is 2.606781093970589\n",
      "Adjusting learning rate of group 0 to 6.9075e-06.\n",
      "epoch: 74\n",
      "The Model-Train-Time spent  0 min 32.72 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7680027173913043 ;  Loss : Train is  1.9977663300539316e-05 ,Valid is 2.509356089260267\n",
      "Adjusting learning rate of group 0 to 4.8037e-06.\n",
      "epoch: 75\n",
      "The Model-Train-Time spent  0 min 32.70 s\n",
      "Accuracy : Train is 0.9998355263157894 , Valid is 0.7713994565217391 ;  Loss : Train is  0.0006947929725835198 ,Valid is 2.545627018679743\n",
      "Adjusting learning rate of group 0 to 3.0779e-06.\n",
      "epoch: 76\n",
      "The Model-Train-Time spent  0 min 32.49 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.764266304347826 ;  Loss : Train is  1.061701853024332e-05 ,Valid is 2.548193465108457\n",
      "Adjusting learning rate of group 0 to 1.7329e-06.\n",
      "epoch: 77\n",
      "The Model-Train-Time spent  0 min 33.40 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7659646739130435 ;  Loss : Train is  2.5392951149689526e-06 ,Valid is 2.6215231211289116\n",
      "Adjusting learning rate of group 0 to 7.7067e-07.\n",
      "epoch: 78\n",
      "The Model-Train-Time spent  0 min 33.61 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7734375 ;  Loss : Train is  5.8681037473051174e-05 ,Valid is 2.5653942253278648\n",
      "Adjusting learning rate of group 0 to 1.9274e-07.\n",
      "epoch: 79\n",
      "The Model-Train-Time spent  0 min 32.66 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7686820652173912 ;  Loss : Train is  2.975153099549444e-05 ,Valid is 2.5905312818029653\n",
      "Adjusting learning rate of group 0 to 0.0000e+00.\n",
      "epoch: 80\n",
      "The Model-Train-Time spent  0 min 33.08 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7717391304347826 ;  Loss : Train is  7.586436052071421e-06 ,Valid is 2.5918635440909346\n",
      "Adjusting learning rate of group 0 to 1.9274e-07.\n",
      "epoch: 81\n",
      "The Model-Train-Time spent  0 min 32.52 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7703804347826086 ;  Loss : Train is  5.247600768741808e-06 ,Valid is 2.5740712103636367\n",
      "Adjusting learning rate of group 0 to 7.7067e-07.\n",
      "epoch: 82\n",
      "The Model-Train-Time spent  0 min 33.35 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7713994565217391 ;  Loss : Train is  4.425056670841418e-06 ,Valid is 2.6220198144083438\n",
      "Adjusting learning rate of group 0 to 1.7329e-06.\n",
      "epoch: 83\n",
      "The Model-Train-Time spent  0 min 32.72 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7693614130434783 ;  Loss : Train is  3.362790142235003e-06 ,Valid is 2.540268431539121\n",
      "Adjusting learning rate of group 0 to 3.0779e-06.\n",
      "epoch: 84\n",
      "The Model-Train-Time spent  0 min 33.32 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.766983695652174 ;  Loss : Train is  1.0100418799801877e-05 ,Valid is 2.5687062636665674\n",
      "Adjusting learning rate of group 0 to 4.8037e-06.\n",
      "epoch: 85\n",
      "The Model-Train-Time spent  0 min 31.93 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7683423913043478 ;  Loss : Train is  3.738162156782652e-06 ,Valid is 2.5726086212241133\n",
      "Adjusting learning rate of group 0 to 6.9075e-06.\n",
      "epoch: 86\n",
      "The Model-Train-Time spent  0 min 32.25 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7676630434782609 ;  Loss : Train is  3.5727396607398985e-06 ,Valid is 2.587556481361389\n",
      "Adjusting learning rate of group 0 to 9.3862e-06.\n",
      "epoch: 87\n",
      "The Model-Train-Time spent  0 min 32.67 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7601902173913043 ;  Loss : Train is  1.1934722332577956e-05 ,Valid is 2.5837773602941763\n",
      "Adjusting learning rate of group 0 to 1.2236e-05.\n",
      "epoch: 88\n",
      "The Model-Train-Time spent  0 min 32.82 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7690217391304348 ;  Loss : Train is  1.0114947431965877e-06 ,Valid is 2.615616150524305\n",
      "Adjusting learning rate of group 0 to 1.5452e-05.\n",
      "epoch: 89\n",
      "The Model-Train-Time spent  0 min 32.79 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7629076086956521 ;  Loss : Train is  2.2121636491072806e-05 ,Valid is 2.608933796053347\n",
      "Adjusting learning rate of group 0 to 1.9030e-05.\n",
      "epoch: 90\n",
      "The Model-Train-Time spent  0 min 32.76 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7700407608695652 ;  Loss : Train is  1.1390565257323415e-06 ,Valid is 2.643597017163816\n",
      "Adjusting learning rate of group 0 to 2.2964e-05.\n",
      "epoch: 91\n",
      "The Model-Train-Time spent  0 min 34.31 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7713994565217391 ;  Loss : Train is  1.3161842760286832e-06 ,Valid is 2.6184699742690376\n",
      "Adjusting learning rate of group 0 to 2.7248e-05.\n",
      "epoch: 92\n",
      "The Model-Train-Time spent  0 min 32.79 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7761548913043478 ;  Loss : Train is  2.006087452173233e-05 ,Valid is 2.5479029106057207\n",
      "覆盖最好的模型...\n",
      "Adjusting learning rate of group 0 to 3.1876e-05.\n",
      "epoch: 93\n",
      "The Model-Train-Time spent  0 min 32.53 s\n",
      "Accuracy : Train is 0.9999177631578947 , Valid is 0.7686820652173912 ;  Loss : Train is  0.00014912485096015427 ,Valid is 2.6039727148802383\n",
      "Adjusting learning rate of group 0 to 3.6840e-05.\n",
      "epoch: 94\n",
      "The Model-Train-Time spent  0 min 32.89 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7659646739130435 ;  Loss : Train is  2.2363211763532536e-06 ,Valid is 2.6685310032056724\n",
      "Adjusting learning rate of group 0 to 4.2133e-05.\n",
      "epoch: 95\n",
      "The Model-Train-Time spent  0 min 32.54 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7676630434782609 ;  Loss : Train is  5.494205183104465e-06 ,Valid is 2.69548617756885\n",
      "Adjusting learning rate of group 0 to 4.7746e-05.\n",
      "epoch: 96\n",
      "The Model-Train-Time spent  0 min 32.64 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7663043478260869 ;  Loss : Train is  3.9497194321532e-06 ,Valid is 2.692834646805473\n",
      "Adjusting learning rate of group 0 to 5.3671e-05.\n",
      "epoch: 97\n",
      "The Model-Train-Time spent  0 min 32.69 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7730978260869565 ;  Loss : Train is  7.312137045358357e-06 ,Valid is 2.675859746725663\n",
      "Adjusting learning rate of group 0 to 5.9899e-05.\n",
      "epoch: 98\n",
      "The Model-Train-Time spent  0 min 33.41 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7741168478260869 ;  Loss : Train is  4.175021068045967e-06 ,Valid is 2.74397263319596\n",
      "Adjusting learning rate of group 0 to 6.6419e-05.\n",
      "epoch: 99\n",
      "The Model-Train-Time spent  0 min 32.57 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7693614130434783 ;  Loss : Train is  7.342007991514708e-06 ,Valid is 2.7938719314077627\n",
      "Adjusting learning rate of group 0 to 7.3223e-05.\n",
      "epoch: 100\n",
      "The Model-Train-Time spent  0 min 32.74 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7676630434782609 ;  Loss : Train is  1.5251632583768743e-06 ,Valid is 2.849858714186627\n",
      "Adjusting learning rate of group 0 to 8.0300e-05.\n",
      "epoch: 101\n",
      "The Model-Train-Time spent  0 min 32.68 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7724184782608695 ;  Loss : Train is  1.184890340817602e-05 ,Valid is 2.8779166885044263\n",
      "Adjusting learning rate of group 0 to 8.7638e-05.\n",
      "epoch: 102\n",
      "The Model-Train-Time spent  0 min 32.70 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7693614130434783 ;  Loss : Train is  7.852431582777124e-06 ,Valid is 2.8487499174864395\n",
      "Adjusting learning rate of group 0 to 9.5227e-05.\n",
      "epoch: 103\n",
      "The Model-Train-Time spent  0 min 32.76 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7663043478260869 ;  Loss : Train is  2.1100436386309174e-06 ,Valid is 2.9791440497273984\n",
      "Adjusting learning rate of group 0 to 1.0305e-04.\n",
      "epoch: 104\n",
      "The Model-Train-Time spent  0 min 32.77 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7673233695652174 ;  Loss : Train is  2.0278264817438626e-05 ,Valid is 3.0156589694645093\n",
      "Adjusting learning rate of group 0 to 1.1111e-04.\n",
      "epoch: 105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Model-Train-Time spent  0 min 32.68 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7676630434782609 ;  Loss : Train is  7.20924060595663e-06 ,Valid is 3.001546989316526\n",
      "Adjusting learning rate of group 0 to 1.1938e-04.\n",
      "epoch: 106\n",
      "The Model-Train-Time spent  0 min 32.76 s\n",
      "Accuracy : Train is 0.9999177631578947 , Valid is 0.7615489130434783 ;  Loss : Train is  0.00022892481402346962 ,Valid is 3.0268928901008936\n",
      "Adjusting learning rate of group 0 to 1.2784e-04.\n",
      "epoch: 107\n",
      "The Model-Train-Time spent  0 min 32.71 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7646059782608695 ;  Loss : Train is  6.212960732610602e-06 ,Valid is 3.09780998851942\n",
      "Adjusting learning rate of group 0 to 1.3650e-04.\n",
      "epoch: 108\n",
      "The Model-Train-Time spent  0 min 32.61 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7703804347826086 ;  Loss : Train is  8.039794077998713e-06 ,Valid is 3.1269134283065796\n",
      "Adjusting learning rate of group 0 to 1.4534e-04.\n",
      "epoch: 109\n",
      "The Model-Train-Time spent  0 min 32.62 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7663043478260869 ;  Loss : Train is  7.067463899913587e-06 ,Valid is 3.213083562643632\n",
      "Adjusting learning rate of group 0 to 1.5433e-04.\n",
      "epoch: 110\n",
      "The Model-Train-Time spent  0 min 32.71 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7666440217391304 ;  Loss : Train is  2.686483295340287e-06 ,Valid is 3.1878671386967534\n",
      "Adjusting learning rate of group 0 to 1.6347e-04.\n",
      "epoch: 111\n",
      "The Model-Train-Time spent  0 min 31.73 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7676630434782609 ;  Loss : Train is  2.61150692638598e-06 ,Valid is 3.151079685791679\n",
      "Adjusting learning rate of group 0 to 1.7275e-04.\n",
      "epoch: 112\n",
      "The Model-Train-Time spent  0 min 32.69 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.766983695652174 ;  Loss : Train is  9.031976132016433e-06 ,Valid is 3.179610153903132\n",
      "Adjusting learning rate of group 0 to 1.8214e-04.\n",
      "epoch: 113\n",
      "The Model-Train-Time spent  0 min 31.95 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7635869565217391 ;  Loss : Train is  7.319378813630656e-05 ,Valid is 3.2138703128565913\n",
      "Adjusting learning rate of group 0 to 1.9164e-04.\n",
      "epoch: 114\n",
      "The Model-Train-Time spent  0 min 31.90 s\n",
      "Accuracy : Train is 0.9998355263157894 , Valid is 0.7646059782608695 ;  Loss : Train is  0.00047690193904073613 ,Valid is 3.3303924228834068\n",
      "Adjusting learning rate of group 0 to 2.0123e-04.\n",
      "epoch: 115\n",
      "The Model-Train-Time spent  0 min 31.79 s\n",
      "Accuracy : Train is 0.9926809210526315 , Valid is 0.720108695652174 ;  Loss : Train is  0.05052525057996574 ,Valid is 4.420461250388104\n",
      "Adjusting learning rate of group 0 to 2.1089e-04.\n",
      "epoch: 116\n",
      "The Model-Train-Time spent  0 min 31.99 s\n",
      "Accuracy : Train is 0.9561677631578948 , Valid is 0.7323369565217391 ;  Loss : Train is  0.23971863489990172 ,Valid is 3.217552610065626\n",
      "Adjusting learning rate of group 0 to 2.2062e-04.\n",
      "epoch: 117\n",
      "The Model-Train-Time spent  0 min 31.88 s\n",
      "Accuracy : Train is 0.9678453947368421 , Valid is 0.7353940217391304 ;  Loss : Train is  0.14139934575283214 ,Valid is 2.6240668296813965\n",
      "Adjusting learning rate of group 0 to 2.3039e-04.\n",
      "epoch: 118\n",
      "The Model-Train-Time spent  0 min 31.90 s\n",
      "Accuracy : Train is 0.9746710526315789 , Valid is 0.7411684782608695 ;  Loss : Train is  0.09651965200901032 ,Valid is 2.2465620559194814\n",
      "Adjusting learning rate of group 0 to 2.4019e-04.\n",
      "epoch: 119\n",
      "The Model-Train-Time spent  0 min 31.82 s\n",
      "Accuracy : Train is 0.9767269736842105 , Valid is 0.7384510869565217 ;  Loss : Train is  0.08492081482943735 ,Valid is 2.1392485628957334\n",
      "Adjusting learning rate of group 0 to 2.5000e-04.\n",
      "epoch: 120\n",
      "The Model-Train-Time spent  0 min 31.80 s\n",
      "Accuracy : Train is 0.9819901315789473 , Valid is 0.7350543478260869 ;  Loss : Train is  0.061226285229388035 ,Valid is 2.0416602881058403\n",
      "Adjusting learning rate of group 0 to 2.5981e-04.\n",
      "epoch: 121\n",
      "The Model-Train-Time spent  0 min 31.87 s\n",
      "Accuracy : Train is 0.9805921052631579 , Valid is 0.7401494565217391 ;  Loss : Train is  0.06371953052125479 ,Valid is 1.9125134115633757\n",
      "Adjusting learning rate of group 0 to 2.6961e-04.\n",
      "epoch: 122\n",
      "The Model-Train-Time spent  0 min 33.43 s\n",
      "Accuracy : Train is 0.9797697368421052 , Valid is 0.7462635869565217 ;  Loss : Train is  0.0630289266180051 ,Valid is 1.8657626276430876\n",
      "Adjusting learning rate of group 0 to 2.7938e-04.\n",
      "epoch: 123\n",
      "The Model-Train-Time spent  0 min 31.94 s\n",
      "Accuracy : Train is 0.9800164473684211 , Valid is 0.749320652173913 ;  Loss : Train is  0.0592821354046464 ,Valid is 1.9157052869382112\n",
      "Adjusting learning rate of group 0 to 2.8911e-04.\n",
      "epoch: 124\n",
      "The Model-Train-Time spent  0 min 31.63 s\n",
      "Accuracy : Train is 0.9865131578947368 , Valid is 0.748641304347826 ;  Loss : Train is  0.039818844238394185 ,Valid is 1.8644166407377825\n",
      "Adjusting learning rate of group 0 to 2.9877e-04.\n",
      "epoch: 125\n",
      "The Model-Train-Time spent  0 min 32.39 s\n",
      "Accuracy : Train is 0.9853618421052631 , Valid is 0.7496603260869565 ;  Loss : Train is  0.047038367086727366 ,Valid is 1.74862511779951\n",
      "Adjusting learning rate of group 0 to 3.0836e-04.\n",
      "epoch: 126\n",
      "The Model-Train-Time spent  0 min 31.94 s\n",
      "Accuracy : Train is 0.9869243421052631 , Valid is 0.7527173913043478 ;  Loss : Train is  0.04281946514782153 ,Valid is 1.770442361417024\n",
      "Adjusting learning rate of group 0 to 3.1786e-04.\n",
      "epoch: 127\n",
      "The Model-Train-Time spent  0 min 31.82 s\n",
      "Accuracy : Train is 0.9856085526315789 , Valid is 0.7540760869565217 ;  Loss : Train is  0.04262120640395503 ,Valid is 1.8107716389324353\n",
      "Adjusting learning rate of group 0 to 3.2725e-04.\n",
      "epoch: 128\n",
      "The Model-Train-Time spent  0 min 31.98 s\n",
      "Accuracy : Train is 0.9855263157894737 , Valid is 0.7527173913043478 ;  Loss : Train is  0.045332074479052895 ,Valid is 1.6735451169635938\n",
      "Adjusting learning rate of group 0 to 3.3653e-04.\n",
      "epoch: 129\n",
      "The Model-Train-Time spent  0 min 31.93 s\n",
      "Accuracy : Train is 0.9862664473684211 , Valid is 0.7554347826086957 ;  Loss : Train is  0.04100933866085191 ,Valid is 1.7235155157420947\n",
      "Adjusting learning rate of group 0 to 3.4567e-04.\n",
      "epoch: 130\n",
      "The Model-Train-Time spent  0 min 31.80 s\n",
      "Accuracy : Train is 0.9856085526315789 , Valid is 0.7445652173913043 ;  Loss : Train is  0.04242724993903386 ,Valid is 1.757469705913378\n",
      "Adjusting learning rate of group 0 to 3.5466e-04.\n",
      "epoch: 131\n",
      "The Model-Train-Time spent  0 min 31.93 s\n",
      "Accuracy : Train is 0.9850328947368421 , Valid is 0.7516983695652174 ;  Loss : Train is  0.044216758120608955 ,Valid is 1.6612502129181572\n",
      "Adjusting learning rate of group 0 to 3.6350e-04.\n",
      "epoch: 132\n",
      "The Model-Train-Time spent  0 min 31.84 s\n",
      "Accuracy : Train is 0.9853618421052631 , Valid is 0.7588315217391304 ;  Loss : Train is  0.042073148920347817 ,Valid is 1.8268431891565737\n",
      "Adjusting learning rate of group 0 to 3.7216e-04.\n",
      "epoch: 133\n",
      "The Model-Train-Time spent  0 min 31.84 s\n",
      "Accuracy : Train is 0.9860197368421052 , Valid is 0.748641304347826 ;  Loss : Train is  0.04461809094799192 ,Valid is 1.7845523772032366\n",
      "Adjusting learning rate of group 0 to 3.8062e-04.\n",
      "epoch: 134\n",
      "The Model-Train-Time spent  0 min 31.96 s\n",
      "Accuracy : Train is 0.9857730263157894 , Valid is 0.7398097826086957 ;  Loss : Train is  0.03994928781727427 ,Valid is 1.80057546366816\n",
      "Adjusting learning rate of group 0 to 3.8889e-04.\n",
      "epoch: 135\n",
      "The Model-Train-Time spent  0 min 31.85 s\n",
      "Accuracy : Train is 0.9865131578947368 , Valid is 0.7544157608695652 ;  Loss : Train is  0.0393709184503869 ,Valid is 1.87343822873157\n",
      "Adjusting learning rate of group 0 to 3.9695e-04.\n",
      "epoch: 136\n",
      "The Model-Train-Time spent  0 min 31.79 s\n",
      "Accuracy : Train is 0.9825657894736842 , Valid is 0.7432065217391304 ;  Loss : Train is  0.055526434787009894 ,Valid is 1.7112139567084934\n",
      "Adjusting learning rate of group 0 to 4.0477e-04.\n",
      "epoch: 137\n",
      "The Model-Train-Time spent  0 min 31.81 s\n",
      "Accuracy : Train is 0.9931743421052631 , Valid is 0.7663043478260869 ;  Loss : Train is  0.021693505699697295 ,Valid is 1.7228853754375293\n",
      "Adjusting learning rate of group 0 to 4.1236e-04.\n",
      "epoch: 138\n",
      "The Model-Train-Time spent  0 min 31.64 s\n",
      "Accuracy : Train is 0.9967105263157895 , Valid is 0.7584918478260869 ;  Loss : Train is  0.010035220376755062 ,Valid is 1.8831748521846274\n",
      "Adjusting learning rate of group 0 to 4.1970e-04.\n",
      "epoch: 139\n",
      "The Model-Train-Time spent  0 min 31.85 s\n",
      "Accuracy : Train is 0.9946546052631579 , Valid is 0.764266304347826 ;  Loss : Train is  0.014722195248070516 ,Valid is 1.9384398875029192\n",
      "Adjusting learning rate of group 0 to 4.2678e-04.\n",
      "epoch: 140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Model-Train-Time spent  0 min 31.80 s\n",
      "Accuracy : Train is 0.9961348684210526 , Valid is 0.7615489130434783 ;  Loss : Train is  0.012185787733056043 ,Valid is 2.0754272263983022\n",
      "Adjusting learning rate of group 0 to 4.3358e-04.\n",
      "epoch: 141\n",
      "The Model-Train-Time spent  0 min 31.86 s\n",
      "Accuracy : Train is 0.9944078947368421 , Valid is 0.7452445652173912 ;  Loss : Train is  0.01767963873908708 ,Valid is 2.1878096746361773\n",
      "Adjusting learning rate of group 0 to 4.4010e-04.\n",
      "epoch: 142\n",
      "The Model-Train-Time spent  0 min 31.86 s\n",
      "Accuracy : Train is 0.9944901315789474 , Valid is 0.7510190217391304 ;  Loss : Train is  0.01727215717301557 ,Valid is 2.09852919889533\n",
      "Adjusting learning rate of group 0 to 4.4633e-04.\n",
      "epoch: 143\n",
      "The Model-Train-Time spent  0 min 31.91 s\n",
      "Accuracy : Train is 0.9942434210526315 , Valid is 0.7483016304347826 ;  Loss : Train is  0.017848801044257064 ,Valid is 2.2365041712056035\n",
      "Adjusting learning rate of group 0 to 4.5225e-04.\n",
      "epoch: 144\n",
      "The Model-Train-Time spent  0 min 31.89 s\n",
      "Accuracy : Train is 0.99375 , Valid is 0.7476222826086957 ;  Loss : Train is  0.01915367047645544 ,Valid is 2.2855798576189126\n",
      "Adjusting learning rate of group 0 to 4.5787e-04.\n",
      "epoch: 145\n",
      "The Model-Train-Time spent  0 min 31.87 s\n",
      "Accuracy : Train is 0.9916118421052631 , Valid is 0.7472826086956521 ;  Loss : Train is  0.026012440839488254 ,Valid is 2.3092157788898633\n",
      "Adjusting learning rate of group 0 to 4.6316e-04.\n",
      "epoch: 146\n",
      "The Model-Train-Time spent  0 min 32.48 s\n",
      "Accuracy : Train is 0.9924342105263158 , Valid is 0.7561141304347826 ;  Loss : Train is  0.02488677338942101 ,Valid is 2.258387741835221\n",
      "Adjusting learning rate of group 0 to 4.6812e-04.\n",
      "epoch: 147\n",
      "The Model-Train-Time spent  0 min 31.90 s\n",
      "Accuracy : Train is 0.9917763157894737 , Valid is 0.7598505434782609 ;  Loss : Train is  0.030040271305724193 ,Valid is 2.1921462131583174\n",
      "Adjusting learning rate of group 0 to 4.7275e-04.\n",
      "epoch: 148\n",
      "The Model-Train-Time spent  0 min 32.50 s\n",
      "Accuracy : Train is 0.9916940789473684 , Valid is 0.7496603260869565 ;  Loss : Train is  0.02690870693247569 ,Valid is 2.243799178496651\n",
      "Adjusting learning rate of group 0 to 4.7704e-04.\n",
      "epoch: 149\n",
      "The Model-Train-Time spent  0 min 31.86 s\n",
      "Accuracy : Train is 0.9893092105263158 , Valid is 0.7428668478260869 ;  Loss : Train is  0.034065474011003974 ,Valid is 2.222032661023347\n",
      "Adjusting learning rate of group 0 to 4.8097e-04.\n",
      "epoch: 150\n",
      "The Model-Train-Time spent  0 min 31.90 s\n",
      "Accuracy : Train is 0.9899671052631579 , Valid is 0.7496603260869565 ;  Loss : Train is  0.03333213442054234 ,Valid is 2.2377871067627617\n",
      "Adjusting learning rate of group 0 to 4.8455e-04.\n",
      "epoch: 151\n",
      "The Model-Train-Time spent  0 min 31.82 s\n",
      "Accuracy : Train is 0.9880756578947368 , Valid is 0.748641304347826 ;  Loss : Train is  0.03783125781307095 ,Valid is 2.2066090210624365\n",
      "Adjusting learning rate of group 0 to 4.8776e-04.\n",
      "epoch: 152\n",
      "The Model-Train-Time spent  0 min 31.95 s\n",
      "Accuracy : Train is 0.9879111842105263 , Valid is 0.7472826086956521 ;  Loss : Train is  0.036012441557096805 ,Valid is 2.208922127018804\n",
      "Adjusting learning rate of group 0 to 4.9061e-04.\n",
      "epoch: 153\n",
      "The Model-Train-Time spent  0 min 31.83 s\n",
      "Accuracy : Train is 0.9868421052631579 , Valid is 0.7323369565217391 ;  Loss : Train is  0.040717961668576066 ,Valid is 2.184966154720472\n",
      "Adjusting learning rate of group 0 to 4.9309e-04.\n",
      "epoch: 154\n",
      "The Model-Train-Time spent  0 min 31.84 s\n",
      "Accuracy : Train is 0.9890625 , Valid is 0.7506793478260869 ;  Loss : Train is  0.03589762651214474 ,Valid is 2.1967115454051807\n",
      "Adjusting learning rate of group 0 to 4.9520e-04.\n",
      "epoch: 155\n",
      "The Model-Train-Time spent  0 min 32.47 s\n",
      "Accuracy : Train is 0.9860197368421052 , Valid is 0.751358695652174 ;  Loss : Train is  0.0462199650116657 ,Valid is 2.067631255025449\n",
      "Adjusting learning rate of group 0 to 4.9692e-04.\n",
      "epoch: 156\n",
      "The Model-Train-Time spent  0 min 32.00 s\n",
      "Accuracy : Train is 0.9884868421052632 , Valid is 0.7387907608695652 ;  Loss : Train is  0.039558950968478855 ,Valid is 2.0192233272220776\n",
      "Adjusting learning rate of group 0 to 4.9827e-04.\n",
      "epoch: 157\n",
      "The Model-Train-Time spent  0 min 31.88 s\n",
      "Accuracy : Train is 0.9870065789473684 , Valid is 0.7506793478260869 ;  Loss : Train is  0.042042003954319576 ,Valid is 2.0280847186627597\n",
      "Adjusting learning rate of group 0 to 4.9923e-04.\n",
      "epoch: 158\n",
      "The Model-Train-Time spent  0 min 31.92 s\n",
      "Accuracy : Train is 0.9888980263157895 , Valid is 0.7544157608695652 ;  Loss : Train is  0.03496752674446294 ,Valid is 1.9267037329466448\n",
      "Adjusting learning rate of group 0 to 4.9981e-04.\n",
      "epoch: 159\n",
      "The Model-Train-Time spent  0 min 32.49 s\n",
      "Accuracy : Train is 0.9863486842105262 , Valid is 0.7530570652173912 ;  Loss : Train is  0.042286670511882556 ,Valid is 1.8961207037386687\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "epoch: 160\n",
      "The Model-Train-Time spent  0 min 31.80 s\n",
      "Accuracy : Train is 0.9867598684210526 , Valid is 0.7530570652173912 ;  Loss : Train is  0.04317332484612339 ,Valid is 2.021326401959295\n",
      "Adjusting learning rate of group 0 to 4.9981e-04.\n",
      "epoch: 161\n",
      "The Model-Train-Time spent  0 min 31.82 s\n",
      "Accuracy : Train is 0.9868421052631579 , Valid is 0.7550951086956521 ;  Loss : Train is  0.04287487300799081 ,Valid is 1.8127765707347705\n",
      "Adjusting learning rate of group 0 to 4.9923e-04.\n",
      "epoch: 162\n",
      "The Model-Train-Time spent  0 min 31.95 s\n",
      "Accuracy : Train is 0.9864309210526315 , Valid is 0.7652853260869565 ;  Loss : Train is  0.042769925659032246 ,Valid is 1.7744147362916365\n",
      "Adjusting learning rate of group 0 to 4.9827e-04.\n",
      "epoch: 163\n",
      "The Model-Train-Time spent  0 min 31.88 s\n",
      "Accuracy : Train is 0.9869243421052631 , Valid is 0.7557744565217391 ;  Loss : Train is  0.03937999168901067 ,Valid is 1.8277416151502859\n",
      "Adjusting learning rate of group 0 to 4.9692e-04.\n",
      "epoch: 164\n",
      "The Model-Train-Time spent  0 min 31.93 s\n",
      "Accuracy : Train is 0.9861019736842105 , Valid is 0.7455842391304348 ;  Loss : Train is  0.036982503200047895 ,Valid is 1.923527629479118\n",
      "Adjusting learning rate of group 0 to 4.9520e-04.\n",
      "epoch: 165\n",
      "The Model-Train-Time spent  0 min 31.79 s\n",
      "Accuracy : Train is 0.9863486842105262 , Valid is 0.7506793478260869 ;  Loss : Train is  0.039573893941154605 ,Valid is 1.8096283933390742\n",
      "Adjusting learning rate of group 0 to 4.9309e-04.\n",
      "epoch: 166\n",
      "The Model-Train-Time spent  0 min 31.89 s\n",
      "Accuracy : Train is 0.9855263157894737 , Valid is 0.7540760869565217 ;  Loss : Train is  0.04253760252736117 ,Valid is 1.7278622647990352\n",
      "Adjusting learning rate of group 0 to 4.9061e-04.\n",
      "epoch: 167\n",
      "The Model-Train-Time spent  0 min 32.54 s\n",
      "Accuracy : Train is 0.984046052631579 , Valid is 0.7459239130434783 ;  Loss : Train is  0.05136525150584547 ,Valid is 1.7413427570591802\n",
      "Adjusting learning rate of group 0 to 4.8776e-04.\n",
      "epoch: 168\n",
      "The Model-Train-Time spent  0 min 31.88 s\n",
      "Accuracy : Train is 0.9866776315789474 , Valid is 0.7418478260869565 ;  Loss : Train is  0.03985447965954479 ,Valid is 1.7983163180558577\n",
      "Adjusting learning rate of group 0 to 4.8455e-04.\n",
      "epoch: 169\n",
      "The Model-Train-Time spent  0 min 31.99 s\n",
      "Accuracy : Train is 0.9862664473684211 , Valid is 0.7421875 ;  Loss : Train is  0.03990440695105415 ,Valid is 1.8017061741455742\n",
      "Adjusting learning rate of group 0 to 4.8097e-04.\n",
      "epoch: 170\n",
      "The Model-Train-Time spent  0 min 31.90 s\n",
      "Accuracy : Train is 0.9862664473684211 , Valid is 0.7472826086956521 ;  Loss : Train is  0.04112693218416289 ,Valid is 1.8061592527057813\n",
      "Adjusting learning rate of group 0 to 4.7704e-04.\n",
      "epoch: 171\n",
      "The Model-Train-Time spent  0 min 31.84 s\n",
      "Accuracy : Train is 0.9882401315789473 , Valid is 0.7540760869565217 ;  Loss : Train is  0.031878202006612955 ,Valid is 1.8365690811820652\n",
      "Adjusting learning rate of group 0 to 4.7275e-04.\n",
      "epoch: 172\n",
      "The Model-Train-Time spent  0 min 31.85 s\n",
      "Accuracy : Train is 0.9770559210526315 , Valid is 0.7275815217391304 ;  Loss : Train is  0.07493005908633533 ,Valid is 1.9101671187773994\n",
      "Adjusting learning rate of group 0 to 4.6812e-04.\n",
      "epoch: 173\n",
      "The Model-Train-Time spent  0 min 31.84 s\n",
      "Accuracy : Train is 0.9641447368421052 , Valid is 0.7347146739130435 ;  Loss : Train is  0.11010879166424274 ,Valid is 1.5892168646273406\n",
      "Adjusting learning rate of group 0 to 4.6316e-04.\n",
      "epoch: 174\n",
      "The Model-Train-Time spent  0 min 31.84 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : Train is 0.9725328947368421 , Valid is 0.735733695652174 ;  Loss : Train is  0.08479794928509939 ,Valid is 1.51983976882437\n",
      "Adjusting learning rate of group 0 to 4.5787e-04.\n",
      "epoch: 175\n",
      "The Model-Train-Time spent  0 min 31.84 s\n",
      "Accuracy : Train is 0.9754111842105263 , Valid is 0.7381114130434783 ;  Loss : Train is  0.0702830617561152 ,Valid is 1.4604970164920972\n",
      "Adjusting learning rate of group 0 to 4.5225e-04.\n",
      "epoch: 176\n",
      "The Model-Train-Time spent  0 min 31.92 s\n",
      "Accuracy : Train is 0.9794407894736842 , Valid is 0.7496603260869565 ;  Loss : Train is  0.05746123622122564 ,Valid is 1.3706237518269082\n",
      "Adjusting learning rate of group 0 to 4.4633e-04.\n",
      "epoch: 177\n",
      "The Model-Train-Time spent  0 min 31.96 s\n",
      "Accuracy : Train is 0.9819901315789473 , Valid is 0.7516983695652174 ;  Loss : Train is  0.052670058343363434 ,Valid is 1.603099885194198\n",
      "Adjusting learning rate of group 0 to 4.4010e-04.\n",
      "epoch: 178\n",
      "The Model-Train-Time spent  0 min 31.86 s\n",
      "Accuracy : Train is 0.9825657894736842 , Valid is 0.748641304347826 ;  Loss : Train is  0.05036977301106641 ,Valid is 1.483872571717138\n",
      "Adjusting learning rate of group 0 to 4.3358e-04.\n",
      "epoch: 179\n",
      "The Model-Train-Time spent  0 min 32.49 s\n",
      "Accuracy : Train is 0.9833059210526316 , Valid is 0.7557744565217391 ;  Loss : Train is  0.0478666897078878 ,Valid is 1.5372787558514138\n",
      "Adjusting learning rate of group 0 to 4.2678e-04.\n",
      "epoch: 180\n",
      "The Model-Train-Time spent  0 min 31.94 s\n",
      "Accuracy : Train is 0.9871710526315789 , Valid is 0.7445652173913043 ;  Loss : Train is  0.039161237691970247 ,Valid is 1.633487722148066\n",
      "Adjusting learning rate of group 0 to 4.1970e-04.\n",
      "epoch: 181\n",
      "The Model-Train-Time spent  0 min 31.81 s\n",
      "Accuracy : Train is 0.9879111842105263 , Valid is 0.7442255434782609 ;  Loss : Train is  0.0372641351858252 ,Valid is 1.7104129376618757\n",
      "Adjusting learning rate of group 0 to 4.1236e-04.\n",
      "epoch: 182\n",
      "The Model-Train-Time spent  0 min 31.94 s\n",
      "Accuracy : Train is 0.9857730263157894 , Valid is 0.7550951086956521 ;  Loss : Train is  0.04086229298263788 ,Valid is 1.610735587451769\n",
      "Adjusting learning rate of group 0 to 4.0477e-04.\n",
      "epoch: 183\n",
      "The Model-Train-Time spent  0 min 31.80 s\n",
      "Accuracy : Train is 0.9892269736842105 , Valid is 0.7503396739130435 ;  Loss : Train is  0.029975675713074836 ,Valid is 1.7868236458819846\n",
      "Adjusting learning rate of group 0 to 3.9695e-04.\n",
      "epoch: 184\n",
      "The Model-Train-Time spent  0 min 31.97 s\n",
      "Accuracy : Train is 0.9879111842105263 , Valid is 0.7537364130434783 ;  Loss : Train is  0.036892740977437874 ,Valid is 1.7402902478757112\n",
      "Adjusting learning rate of group 0 to 3.8889e-04.\n",
      "epoch: 185\n",
      "The Model-Train-Time spent  0 min 31.85 s\n",
      "Accuracy : Train is 0.9895559210526316 , Valid is 0.7666440217391304 ;  Loss : Train is  0.03088330795106135 ,Valid is 1.7423235074333523\n",
      "Adjusting learning rate of group 0 to 3.8062e-04.\n",
      "epoch: 186\n",
      "The Model-Train-Time spent  0 min 31.91 s\n",
      "Accuracy : Train is 0.9912006578947368 , Valid is 0.751358695652174 ;  Loss : Train is  0.024286012782862312 ,Valid is 1.7894132551939592\n",
      "Adjusting learning rate of group 0 to 3.7216e-04.\n",
      "epoch: 187\n",
      "The Model-Train-Time spent  0 min 31.83 s\n",
      "Accuracy : Train is 0.9910361842105263 , Valid is 0.7411684782608695 ;  Loss : Train is  0.02415033017138117 ,Valid is 1.8873411054196565\n",
      "Adjusting learning rate of group 0 to 3.6350e-04.\n",
      "epoch: 188\n",
      "The Model-Train-Time spent  0 min 32.43 s\n",
      "Accuracy : Train is 0.9931743421052631 , Valid is 0.7550951086956521 ;  Loss : Train is  0.02060947518207525 ,Valid is 1.8798475369163181\n",
      "Adjusting learning rate of group 0 to 3.5466e-04.\n",
      "epoch: 189\n",
      "The Model-Train-Time spent  0 min 31.85 s\n",
      "Accuracy : Train is 0.9935032894736842 , Valid is 0.7632472826086957 ;  Loss : Train is  0.020939134914231928 ,Valid is 1.9077610243921694\n",
      "Adjusting learning rate of group 0 to 3.4567e-04.\n",
      "epoch: 190\n",
      "The Model-Train-Time spent  0 min 31.96 s\n",
      "Accuracy : Train is 0.9944901315789474 , Valid is 0.7554347826086957 ;  Loss : Train is  0.01474565883216105 ,Valid is 2.002193466476772\n",
      "Adjusting learning rate of group 0 to 3.3653e-04.\n",
      "epoch: 191\n",
      "The Model-Train-Time spent  0 min 31.82 s\n",
      "Accuracy : Train is 0.9947368421052631 , Valid is 0.7697010869565217 ;  Loss : Train is  0.014341802140207667 ,Valid is 2.022344734357751\n",
      "Adjusting learning rate of group 0 to 3.2725e-04.\n",
      "epoch: 192\n",
      "The Model-Train-Time spent  0 min 31.91 s\n",
      "Accuracy : Train is 0.9944078947368421 , Valid is 0.7557744565217391 ;  Loss : Train is  0.016796549889994294 ,Valid is 2.0086111244948013\n",
      "Adjusting learning rate of group 0 to 3.1786e-04.\n",
      "epoch: 193\n",
      "The Model-Train-Time spent  0 min 31.81 s\n",
      "Accuracy : Train is 0.9953124999999999 , Valid is 0.7595108695652174 ;  Loss : Train is  0.013968908845594055 ,Valid is 2.073886617370274\n",
      "Adjusting learning rate of group 0 to 3.0836e-04.\n",
      "epoch: 194\n",
      "The Model-Train-Time spent  0 min 31.87 s\n",
      "Accuracy : Train is 0.9984375 , Valid is 0.7781929347826086 ;  Loss : Train is  0.004878382139692181 ,Valid is 2.0935974017433496\n",
      "覆盖最好的模型...\n",
      "Adjusting learning rate of group 0 to 2.9877e-04.\n",
      "epoch: 195\n",
      "The Model-Train-Time spent  0 min 31.83 s\n",
      "Accuracy : Train is 0.999671052631579 , Valid is 0.7758152173913043 ;  Loss : Train is  0.001398503045110326 ,Valid is 2.1415308351102085\n",
      "Adjusting learning rate of group 0 to 2.8911e-04.\n",
      "epoch: 196\n",
      "The Model-Train-Time spent  0 min 31.88 s\n",
      "Accuracy : Train is 0.9994243421052631 , Valid is 0.7646059782608695 ;  Loss : Train is  0.0024738556362296407 ,Valid is 2.309268324271492\n",
      "Adjusting learning rate of group 0 to 2.7938e-04.\n",
      "epoch: 197\n",
      "The Model-Train-Time spent  0 min 31.82 s\n",
      "Accuracy : Train is 0.9997532894736841 , Valid is 0.7758152173913043 ;  Loss : Train is  0.0007197445454566102 ,Valid is 2.3509734091551406\n",
      "Adjusting learning rate of group 0 to 2.6961e-04.\n",
      "epoch: 198\n",
      "The Model-Train-Time spent  0 min 31.85 s\n",
      "Accuracy : Train is 0.9994243421052631 , Valid is 0.7802309782608695 ;  Loss : Train is  0.0015619437945516485 ,Valid is 2.3839146883591362\n",
      "覆盖最好的模型...\n",
      "Adjusting learning rate of group 0 to 2.5981e-04.\n",
      "epoch: 199\n",
      "The Model-Train-Time spent  0 min 31.87 s\n",
      "Accuracy : Train is 1.0 , Valid is 0.7778532608695652 ;  Loss : Train is  0.00023085232824087142 ,Valid is 2.5019747951756353\n",
      "Adjusting learning rate of group 0 to 2.5000e-04.\n"
     ]
    }
   ],
   "source": [
    "#关于AMP自动精度求解，我也并不是很熟悉，只能使用官方给的实例进行照葫芦画瓢。\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "torch.cuda.empty_cache()\n",
    "for epoch in range(D_epoch, epochs):\n",
    "    time_one = time.time()                         #标记训练开始时间戳\n",
    "    train_acc1 = 0.0\n",
    "    train_loss1 = 0.0\n",
    "    train_acc = 0.0\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    val_acc = 0.0\n",
    "    val_loss = 0.0\n",
    "    number = 0\n",
    "    model.train()\n",
    "    print(\"epoch:\",epoch)\n",
    "\n",
    "    for batchidx , (x ,label) in enumerate(data0_train):\n",
    "        x , label = x.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            y1 = model(x)\n",
    "            loss = criteon(y1,label)  \n",
    "        _, preds1 = torch.max(F.softmax(y1,dim=1), 1)\n",
    "        #AMP优化\n",
    "        scaler.scale(loss).backward()\n",
    "#         loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm = 5, norm_type=2)  #梯度剪裁\n",
    "        scaler.step(optimizer)\n",
    "#         optimizer.step()\n",
    "        scaler.update()\n",
    "        train_loss1 += loss.item()*batch_size\n",
    "        train_acc1 += torch.sum(preds1 == label.data).double()\n",
    "        number = number + 1\n",
    "    time_two = time.time()             #标记训练结束时间戳\n",
    "    #输出训练一轮所需时间，用于分析对比\n",
    "    print(\"The Model-Train-Time spent  %d min %.2f s\"%((time_two-time_one)//60,(time_two-time_one)%60))\n",
    "    #计算训练时候的平均损失和平均准确率\n",
    "    train_loss = train_loss1 / (number*batch_size)\n",
    "    train_acc = train_acc1 / (number*batch_size)\n",
    "    #计算测试时候的平均损失和平均准确率\n",
    "    val_acc, val_loss = evalute_(model, data1_val)\n",
    "    \n",
    "    train_acc = train_acc.cpu()\n",
    "    val_acc = val_acc.cpu()\n",
    "    print('Accuracy : Train is {} , Valid is {} ;  Loss : Train is  {} ,Valid is {}'.format(train_acc, val_acc, train_loss , val_loss))\n",
    "    #如果你不需要训练以及验证的准确率和损失值，你可以注释这下面的两行，它们不是非必须的，理论上只存在于汇报和论文中\n",
    "    dataframe = pd.DataFrame(columns = [epoch,train_acc,train_loss,val_acc, val_loss])\n",
    "    dataframe.to_csv(data_csv_path,line_terminator=\"\\n\",mode='a',index=False,sep=',')\n",
    "    if val_acc > best_acc:\n",
    "        print(\"覆盖最好的模型...\")\n",
    "        best_acc = val_acc \n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'best_acc':best_acc\n",
    "        }\n",
    "        torch.save(checkpoint,model_save_path)\n",
    "#     time_three = time.time() \n",
    "#     print(\"测试花费时间\",time_three-time_two)\n",
    "    scheduler.step()  #动态学习率更新 \n",
    "#如果你不是非必须，我建议你尽量不要使用n折交叉验证，使用数据增强可能效果更优于它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370c8419",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
